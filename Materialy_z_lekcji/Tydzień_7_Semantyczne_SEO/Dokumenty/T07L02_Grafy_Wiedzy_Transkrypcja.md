Dzień dobry. Cześć, mam nadzieję, że żyjecie po poprzedniej lekcji, w której zaadresowałem dużo śmiesznych end i kontekstów anglo, anglojęzycznych słów i wyrażeń bez żadnego połączenia semantycznego ze sobą, pewnie. Od tej lekcji zaczynamy wszystko łączyć w całość na kierunku zbudowania mapy tematycznej i modelowania tematycznego, czym będziemy kończyć ten tydzień. A więc po kolei. W tej lekcji omówimy sobie konteksty grafów wiedzy oraz grafów informacji. Skąd to się wzięło? Google stoi przed wyzwaniem uporządkowania internetu. Ten proces nazywa się information retrieval, czyli wydobywanie informacji z internetu, z waszych stron internetowych. Ale mówiąc o multimodalności, modelach multimodalnych pewnie wydobywanie wiedzy z wideo, z audio, z PDF-ów, z obrazów. I co do zasady Google to robi. Przecież widzicie w AI Overview, że czasami potrafi się pojawić tam YouTube. Information retrieval to już nie jest tylko analiza kontentu. Natomiast zaczynając od początku, Google stał przed jednym wyzwaniem. Pierwsza sprawa. Kontent to jest tylko ciąg znaków ze spacją i należy z niego wydobyć esencję. Wiecie, internet być może, może wyglądać w ten sposób. To jest taka wizualna reprezentacja internetu, żeby wejść w ten temat. Jest po prostu bałagan i Google musi uporządkować internet w taki sposób właśnie do formy grafowej, żeby jedno wynikało z drugiego. Tak jak mówiłem w poprzedniej lekcji o tych zależnościach seed, node, leaf na przykład albo atrybutach basen, basen stelażowy, basen, basen ogrodowy. No to w tym momencie jedno wynika z drugiego. Czyli jeżeli mamy bread crumby na Waszej stronie internetowej, czy jakąś tam strukturę kategorii, no to jedno powinno wynikać z drugiego. Przez to obniżacie koszt przetwarzania, bo Google ma koszt przetwarzania na właśnie ten proces information retrieval. A jeżeli Wasza strona będzie bardziej uporządkowana, to ten koszt będzie niższy, czyli, czyli obniżony koszt, bardziej poukładana strona, Google będzie umiało lepiej wyciągać informacje. No i po to, po to to robimy. No i teraz tak, jak to robi Google tak w telegraficznym skrócie, bo tutaj algorytmy ewoluują. Natomiast pierwsza sprawa to jest jakby tokenizacja, to już wiemy dlaczego, w algorytmach, czy tam używając transformerów, czy Berta, czy po prostu AI. Dlaczego są słowa tokenizowane? To było w pierwszym tygodniu. Usuwane są stop wordy sprowadzanych do najprostszej postaci. Mniej więcej nasze procesy, które będziemy operować, wszystkie będą to zakładać. Oczywiście to będzie działo się automatycznie z wykorzystaniem AI. Natomiast najważniejsze jest to, że Google w tym procesie wyciąga feature extraction, czyli wyciąga te encje, powiązania, atrybuty, relacje, żeby wiedzieć, co jest czym i co, co znaczy. Ponieważ wiemy, że semantyka jest to nadawanie znaczeń, więc mniej więcej w tym, w tym miejscu Google to wyciąga z Waszych strony internetowych, nadaje znaczenia encjom, relacjom i tak dalej, tworząc dwa grafy. Jak już powiedziałem, są dwa grafy. Jeden to jest graf knowledge graph, graf wiedzy, a drugi to jest information graph, graf informacji. Są dwa powody, dlaczego Google tak podzieliło. Przecież można by zrobić to w kontekście jednego grafu dużego, wielkiego. No i właśnie to jest ten problem, że jak Google wyobraźmy sobie dzisiaj, zobaczymy taki duży graf, on jeszcze nie będzie duży, no ale powiedzmy całkiem duży. Zobaczycie to, jeżeli Google w jednym grafie miałoby mieć cały internet i wszystkie informacje i wszystko i Google w tym miałoby szybko przeszukiwać, to, to się nie wydarzy, bo po prostu struktura byłaby za duża. Dlatego Google podzieliło sobie graf wiedzy na Big Picture Helicopter View, czyli połączenie encji, kontekstów ze sobą, czyli np. jak samochód łączy się z motocyklem, albo jak samochód łączy się z łodzią, z łodzią podwodną i graf informacji, gdzie po prostu są konkretne informacje na temat samochodu, motocyklu i łodzi podwodnej. Dlaczego? Bo, bo wiedza to nie jest to samo, co informacja. Bo wiedza ma konteksty, jakieś połączenia, właśnie relacje i jest wiedzą na przykład domenową w jakimś tam obszarze. A informacja jest suchą, daną informacją. Na przykład samochód jest to, samochód jest to, samochód jest to, samochód jest to, samochód może mieć cztery koła, ma cztery koła, też może mieć więcej i na przykład ma silnik. Nie? To jest goła informacja, z której dopiero Google może zbudować wiedzę. Dlatego Google rozróżnia dwa takie grafy. Jeżeli chcemy podejść pod semantykę, musimy o tym pamiętać, że są dwa różne wykorzystanie jednego nie daje nam pełnego pokrycia. Czyli pamiętajmy, że graf wiedzy to jest powiedzmy szerokość, graf wiedzy domenowej, że w naszej, naszej domenie, na przykład motoryzacji są takie konteksty: samochód, łódź podwodna, może łódź podwodna nie, ale łódź, motorówka czy jakiś tam jacht, czy jakieś coś tam. A w temacie grafów informacji jest tak, że to jest głębokość, czyli jak bardzo dany temat, ile ma informacji i to jest dosyć istotne. Czemu Google to buduje? Bo te grafy cały czas ewoluują. Grafy pozwalają dokładać nowe rzeczy, zmieniać relacje. Tak samo wiedza cały czas ewoluuje, bo ciągle jest coś dokładane więcej. I tak to, tak to działa w Google. Zacznijmy po kolei. Zrobimy sobie trening na dwóch takich grafach, gdzie zobaczycie sami, na czym polega ich różnica. I dalej w strategiach contentowych, czy w strategiach semantycznego SEO będzie można te grafy w zupełności fajnie zastosować. Dobra, graf wiedzy po kolei składa się, co do zasady minimalnie z dwóch rzeczy. Natomiast my będziemy robić używając trzech rzeczy, żeby były jeszcze bardziej kompletne, bo takie zastosowanie pozwoli nam robić bardziej semantyczne linkowanie wewnętrzne, co zobaczymy przy pewnie w przyszłym tygodniu przy, przy content briefingu. Natomiast zawsze graf wiedzy będzie składał się z węzła. Może to być nazywane nodem. Będziemy to nazywać encją, bo jesteśmy w semantycznym SEO, czyli mamy kontekst encji, nie słów kluczowych, co do zasady. Więc mamy encje i encje będą się łączyć ze sobą krawędziami.W teorii grafów mówi się o tym edges. My będziemy to nazywać relacją. Co do zasady jest to samo, zmienia się tylko słowo. Czyli na przykład mamy samochód jako jeden, jedna encja, jeden note, motor jako drugi note i relacje między nimi, czyli tą krawędź. Krawędź będzie się nazywała powiedzmy samochód, motor, no i jakaś tam relacja będzie-- są pojazdami. Samochód, samochód i motor są pojazdami. Samochód jest pojazdem jak motor. No nie? To tak szybko wymyśliłem. Te krawędzie są też opisywane słownikowo na potrzeby grafów. Jest zamknięty zestaw typowych krawędzi, typowych relacji w semantyce, które też Wam pokażę. Są w promptach w tym tygodniu i tak też te grafy są opisywane. I ostatnią rzeczą, którą my sobie opisujemy, są właściwości. Tutaj może być properties label, tak to jest nazywane w teorii grafów profesjonalnie. Chodzi o to, że jak mamy samochód i jak mamy motor i one są połączone ze sobą jakąś tam krawędzią, relacją, którą jest na przykład, jest pojazdem, to możemy to opisać na przykład i będziemy opisywać słownie w celu złapania kontekstu. Czyli zarówno motor, jak i samochód są pojazdami kołowymi różniącym się tym, że samochód ma cztery koła, a motor ma dwa, na przykład. No i to jest jakiś opis tej relacji, na podstawie czego jesteśmy w stanie zbudować kontekstowe linkowanie wewnętrzne, bo wiemy, jak co się łączy, z czym, z jakiego powodu. I to jest właśnie ten label, czyli jakiś tam, ee... Mateusz, co znaczy label? Nie pamiętam. Label po angielsku? Etykieta! Przecież, przecież za dużo tych słów ciągle. Label, edge, node, contextual bridge. Label, etykieta. I kolejną etykietą, którą my sobie wprowadzimy do grafów, jest siła powiązania. Bo my chcemy wiedzieć, jak samochód jest silnie powiązany z motorem. No pewnie będzie w kontekście motoryzacji dosyć silnie powiązany. A jak samochód jest powiązany z koniem jako zwierzę? Bowiem z koniem mechanicznym będzie silnie powiązany, a z koniem jako zwierzę no pewnie już bardzo słabo będzie powiązany, jeżeli-- pewnie jakoś będzie, jako środek transportu, ale, ale to powiązanie pewnie będzie dużo słabsze niż w kontekście motoru. Więc jakby będziemy sobie wprowadzać coś takiego, co nam spowoduje, że będziemy budować mapy tematyczne z najbliżej powiązanymi tematami, encjami, atrybutami. Żeby one były najbardziej skupione. Jak pewnie domyślacie, to spowoduje topical authority. Tak więc podsumowanie jeszcze raz: grafy wiedzy składają się z węzłów nodów. My będziemy to nazywać encjami na potrzeby semantycznego SEO, żeby utrzymać terminologię, krawędziami i właściwościami. W naszym przypadku będzie to opis i Mateusz etykieta. Przykładowy graf. Ja zawsze go pokazuję. To powiedzmy w poprzednim tygodniu mówiłem o Central Entity i o tym, że jeżeli procesujemy dany temat, zawsze wychodzimy od tego root entity czy seed entity, czyli central entity. Zwał jak zwał, to ciągle będzie to samo i rozpracowujemy sobie temat w głąb, opisując go jego relacjami, jego innymi sytuacjami. I tutaj właśnie mamy pana Tolkiena, który powiedzmy jest tym central entity i został opisany przez zestaw połączeń i zestaw de facto encji, które znajdują się dookoła niego. Czyli mamy tutaj informację, że pan Tolkien umarł w United Kingdom, czyli umarł w Wielkiej Brytanii. I właśnie widzicie Tolkien to jest właśnie ten note czy węzeł, czy encja United Kingdom. To jest druga encja. No bo Wielka Brytania jest encją jako kraj, a to pomiędzy nimi to jest właśnie to edge, czyli relacja, która jest opisana jako date in. Relacją jest po prostu umarł w no i tak dalej. Tolkien na przykład Legolas created by, czyli to jest jeszcze jedna rzecz, to są strzałeczki, to są kierunki. Bo Tolkien nie był Legolasem w żaden sposób, natomiast Legolas został stworzony przez Tolkiena, czyli tu mamy jakby kierunek logiczny. I to samo stosuje Google. To jest-- też pokazywałem to w poprzedniej konferencji. W sumie zawsze to pokazuję na moich prezentacjach. Dzisiaj to po prostu wejdziemy w to głębiej i będziemy sobie pokazywać to na różnych wizualizacjach. Z patentów Google wyciekła informacja, że Google stosuje coś takiego jak semantic notes. No to no to wiemy, że grafy wiedzy są, składają się z trzech rzeczy: nodów, node'ów, node, nodes, z nodes z edges i-i-i z labels. No i Google o tym mówi, że właśnie te węzły semantyczne, czyli ten semantic notes, ee, jakiegoś tam dokumentu to węzeł skierowanym grafia cyklicznym reprezentowany przez listę sąsiedztwa. Brzmi nieźle, tak samo jak ten moment obrotowy wzbudzenie silnika i tak dalej. Natomiast to mniej więcej działa tak, że mamy te node'y, encje, mamy relacje i jedno zależy od drugiego i jest wskazany kierunek. Acykliczny znaczy, że nie ma cykli. Czyli np. jedno nie wynika. Nasz Orlando Bloom jest Orlando Bloomem, okej, ale nie ma tam żadnych cykli, czyli są acykliczne, czyli jedno kieruje do drugiego, a skierowane dlatego, że są strzałki. No bo, no bo, Tolkien nie jest Legolasem, ale Legolas został stworzony przez Tolkiena, dlatego jest określony kierunek. Jak będę pokazywał Wam wizualizacje grafu wiedzy, no to sobie do tego tematu wrócimy. Więc to jest dokładnie to. O tym mówi ten patent, który wyciekł z Google. I tak Google buduje grafy wiedzy, a my teraz sobie zbudujemy przykładowy graf, żebyśmy zrozumieli, o co chodzi. Ja do tej lekcji przygotowałem Wam zestaw promptów. Akurat tych promptów będziemy używać częściej. Nie będziemy wchodzić w jego.Eee, struktura i logika, każdy z Was sobie to może przeczytać. Natomiast to, co jest tutaj istotne, ym, ja wprowadziłem zestaw słownikowy relacji po to, żeby AI umiało standardowy zestaw relacji, które występują w dużych grafach wiedzy, czyli np. Tutaj są jakieś relacje określające, określające strukturę, czyli S a, czyli coś tam jest czymś albo instance of jest częścią czegoś, albo part of po raz kolejny częścią czegoś czy has part, czy ma jakąś część. To są typowe zestaw słownika relacyjnego w grafach wiedzy jest wprowadzany do tego, do tego promptu. Wcześniej tego nigdzie nie pokazywałem, więc możecie się zapoznać jakie są typowe relacje istniejące między encjami na świecie. Dodatkowo tutaj zrobiliśmy, poczytajcie sobie tą część, co to jest source entity, czyli ta encja wstępna, od której zaczynamy analizę, czyli wiecie jak to się rozgałęzia te tematy. Central Entity Source Entity. Target Entity, czyli jak się łączy, z czym czyli acykliczny, nie łączy się sam ze sobą, tylko source jest inny niż target zawsze. To co Wam powiedziałem te labele wprowadzenie relationship description oraz ten relationship strength, czyli siłę, siłę, siłę relacji. Tutaj sobie wprowadzamy, czyli tutaj mamy powiedzmy to są te nasze node, które pokazywałem na grafie wiedzy. Te relacje tutaj, które są tutaj relationship słownikowe opisane są to nasze edge, czyli relacje, a to są nasze labele, które wprowadzamy, czyli relationship description i relationship strength. To są nasze labele, którymi będziemy opisywać graf wiedzy. I co do zasady graf wiedzy będzie skonfigurowany w następujący sposób. To jest jakby Jason, jakby długo się bawiłem z różnymi formatami, z różnymi modelami językowymi i co do zasady Jason jest najlepszym możliwym formatem do transportu. Pewnie pierwszym naturalnym byłoby, że coś tam jest strzałeczka, coś tam jest, czasem jest strzałeczka. No ale to nie zadziała. Nie utrzymamy tutaj konsystencji danych, a w tym konkretnym przypadku, w który wchodzimy czystość danych, powiedzmy jakość danych jest jakby istotna na koniec tego ćwiczenia, czyli otrzymujemy to source entity relationship, target entity relationship description, czyli label i relationship strength, czyli kolejny, kolejny, kolejny label. Dla naszego procesu wchodzimy następującymi rzeczami: Central Entity, czyli powiedzmy tą encją, która jest centralna, jest najważniejsza. Możemy to zmienić na przykład na powiedzmy albo zostawmy, od której zaczynamy analizę, wokół której jakby analizujemy kontekst i język, w którym operujemy. Możecie sobie zdefiniować, jaki chcecie. My będziemy na razie operować w języku polskim i tu jest jakby taki kontent. My możemy go na potrzeby tego prostego ćwiczenia jakby na chwilę obecną usunąć. Dobra, idziemy do czata. Ja sugeruję tego typu operacje wykonywać na modelach O3, bo one mają trochę reasoningu i te jakości są, jakości odpowiedzi są lepsze i dzisiaj nie będziemy w kontekście kortyzolu. Wyjątkowo dzisiaj będziemy w kontekście samochodów, bo w sumie why not? Wchodzimy na Wikipedię. Jak sobie popatrzycie na linkowanie wewnętrzne i na strukturę jakby artykułu na Wikipedii, to, to jest właśnie graf informacji. Takie rozprowadzenie widzicie kontekstowe w głąb kontekstu, kontekstu samochodu. No jesteśmy jakby na tym głównym węźle, czyli na tej central entity, czyli na samym początku jesteśmy samochodem i ten samochód dopiero zaczyna się rozgałęziać na jakieś tutaj ciągniki siodłowe, no jakieś tam inne rzeczy. No ale okej, to nie o tym. Zachęcam sobie popatrzeć na-- po tym, jak zobaczycie wszystkie lekcje z tego tygodnia, jak jest ustrukturyzowana Wikipedia, to zrozumiecie, jak jest ustrukturyzowana wiedza na świecie. Dobra, kopiujemy sobie content. Na razie tak chałupniczo, ale to na potrzeby tego ćwiczenia jest jakby wystarczająco. Damy go sobie tutaj. I naszym językiem jest język polski. A naszą encją główną, od której rozpoczynamy analitykę jest samochód. Dobra, to jest nasz, nasz prąd, nasze zadanie. Idziemy z tym do czata. No i niech się dzieje. Teraz sobie model chwileczkę pomyśli. Dobra, mamy to. Wracamy. Mamy jakiś graf wiedzy. Jak widzimy, on jest dosyć malutki. Dlaczego? No bo input, czyli ten korpus danych, który wprowadziliśmy, był dosyć, dosyć mały. Ale poprzyglądajmy się, co tu widzimy. Przede wszystkim te relacje są po angielsku, dlatego, że usztandaryzowałem do słownika takiego typowego dla grafów wiedzy, żeby to wszystko było dalej w jednym standardzie zobaczycie dlaczego. No i powiedzmy, ee, samochód is a, czyli jest kołowy pojazd silnikowy. Nice. Czyli już wiemy jak samochód się łączy z kołowym pojazdem silnikowym, co stanowi encję, bo kołowy pojazd silnikowy to pewnie też jest, no czołg nie, ale jakaś amfibia to pewnie, pewnie już tak, nie? Czy samochód has part silnik. Czyli widzicie, po raz kolejny mamy big picture, samochód, encja silnik i samochód ma silnik. Natomiast silnik ma też samolot i wiele, wiele innych rzeczy, co będzie się dalej łączyć. I w ten sposób jakby na poziomie wiedzowym jest to, jest to operowane. Na chwileczkę sobie zostawimy. Albo o, samochód uses napęd hybrydowy, czyli samochód posiada napęd hybrydowy. A napęd hybrydowy pewnie posiada dużo innych rzeczy. Jest to malutki grafik, bo wiedza była malutka. On zawiera powiedzmy dwanaście node'ów Source Entity, więc jak jest malutka na samym końcu ćwiczenia zobaczycie takie troszeczkę większe. Dobra, tyle o grafach wiedzy. Podsumowując big picture połączenie encji wiedza i to jest doskonałe właśnie do zbudowania.Y Topical mapy i struktury. No bo Google tak sobie buduje strukturę, tak sobie buduje wiedzę. Więc my trochę będziemy dzisiaj odtwarzać proces Google na modelach Gemini. Oczywiście Google jest dużo mądrzejsze niż, niż my i ma więcej algorytmów, ale mniej więcej logika będzie bardzo, bardzo zbliżona. Dobra, chodźmy dalej. To są grafy wiedzy. Teraz poczujmy różnicę między grafem wiedzy, a grafem informacji. To jest bardzo istotne. Graf wiedzy składał się z node'ów, edge, node'ów i labeli. Graf informacji składa się z subject predicate object, czyli z tematu predykatu i jakiegoś tam obiektu. Niby podobnie, bo też to jest trójnik. Natomiast jakby tu jest troszeczkę inny poziom szczegółu i głębokości, bo tutaj będziemy mieli jabłko jest owocem, jabłko jest czerwone, jabłko jest smaczne, jabłko jest słodkie, jabłko rośnie na drzewie, jabłko i tak dalej. Chodzi o to, że w ten sposób jest zbudowana każda informacja na świecie. Jakby stosując tak dużo tych trójników, wchodząc w głąb, bo cały czas jesteśmy w głąb tematu jabłka, jesteśmy w stanie opisać całą wiedzę istniejącą na świecie. Tak dokładnie jest zbudowana Wikidata, czyli odpowiednik Wikipedii. Po tym ćwiczeniu popatrzcie sobie na, znaczy po tym tygodniu popatrzcie sobie na budowę Wikidaty i popatrzcie sobie na budowę Wikipedii i linkowania kontekstowego, wewnętrznego, ich struktury i zależności. To Wam dużo się wyjaśni, czemu to jest tak stworzone. Cała Wikidata jest stworzona, to jest taka liczba sto siedem, sto siedem milionów właśnie tych predykatów, czyli sto siedem milionów predykatów takich jest reprezentacją całej wiedzy dostępnej na Wikidacie. Działa to mniej więcej w następujący sposób. Mamy powiedzmy ten dziesięć na dziesięć PhotoBook to jest jakiś tam album fotograficzny, jest połączony, czy firma jest jakaś akurat w tym kontekście akurat, czyli PhotoBook is instance of Non Profit Organization, czyli jest organizacja Non profit Inception dwa tysiące dwanaście, czyli stworzony w dwa tysiące dwanaście i dzięki połączeniu, to są de facto dwa, dwa, dwa trójniki, bo jest PhotoBook, Inception i dwa tysiące dwanaście i Photobooks Instance of Non Profit Organization. Czyli mamy dwa trójniki semantyczne subject predicate object. Ich połączenie stworzyło, stworzyło właśnie to, to pierwsze zdanie, co widzimy. Mam nadzieję, że mam to podkreślone tutaj i werbalizacja jakimś modelem językowym zrobiła zdanie konkretną statement, co to jest ten PhotoBook. Tym się nie zajmujemy w tym tygodniu, tym będziemy się zajmować w przyszłym tygodniu przy generowaniu contentu. Natomiast ten content zawsze będzie generowany z tego, a przynajmniej briefy contentowe właśnie z głębokości informacji. Zróbmy sobie ćwiczenie, żeby zrozumieć różnicę między grafem wiedzy i grafem informacji. Przygotowałem Wam kolejny prompt. Będziemy poruszać się cały czas w JSONie. Natomiast to, co jest najważniejsze, robimy sobie ekstrakcję predicate. Do struktury subject predicate object. Tak jak pokazałem na początku w prezentacji Google robi ten feature extraction. To jest właśnie to, co właśnie tutaj sobie operujemy. I widzimy, że tutaj jest key information relationship with it, żeby się umieścił w danej informacji i zawsze mówimy, jak mówimy gra w informacji to gra w informacje, gra w wiedzę to gra w wiedzę. A ja rozumiem różnice między nimi. Wszystko ekstrahujemy do takiego postaci. Subject predicate object. No i ok. Jak tutaj działamy? Tutaj w tym momencie nie mamy analizy central entity, seed entity i rozpraszania się, bo wiedza, bo informacja jest informacją, czyli nam nie zależy analityka na kierunku jakiejś tam rozbudowy NC czy otoczenia NC, tylko wyciągnięcia wszystkich informacji. Więc w tym przypadku nie dajemy frazy, do której będziemy robić ekstrakcję czy jakąś tam analitykę. Dajemy tylko język, że jesteśmy w języku polskim i co do zasady tylko nasz content. Czyli skopiujmy sobie jeszcze raz content z Wikipedii. Ten prompt, który macie udostępniony pod lekcjami dotyczących budowy grafów, zachęca o semantic triples information graph represented as a set of semantic triples, czyli graf informacji reprezentowany przez zestaw trójników semantycznych. Idziemy do AI na razie takie proste ćwiczenia, które są w zasięgu wszystkich. Mam nadzieję, że wszystkie zrealizujecie z tego tygodnia. A i teraz nam powstanie graf informacji i porównamy sobie różnice. No dobra, mamy ten graf. Jak widzimy tutaj na Wikipedii jest trochę więcej, on się jeszcze generuje. Ok, więcej informacji i tak powinno być. Skopiujmy sobie go do notatnika, żeby mu się poprzyglądać i zobaczcie. Samochód subject predicate jest rodzajem kołowego pojazdu silnikowego. No to już wiemy. Natomiast zobaczcie tutaj mamy dużo głębszy zestaw informacji, jak się dzielą samochody. Tam nie mieliśmy jak się dzielą samochody pewnie jakby troszeczkę głębiej poanalizować, to też by nam się podzieliło jako NC czy jakieś atrybuty NC. Więc jakby spoko. Natomiast tutaj znajduje się dużo więcej informacji zawartej w contencie bezpośrednio, czyli subject powiedzmy silnik spalinowy predicate wykorzystuje object benzyny lub olej napędowy. Tutaj nie zbudujemy z czegoś takiego mapy tematycznej, natomiast z tego zbudujemy content, bo tutaj są po prostu widzicie, to nie są NC, to są jakieś statementy, subjecty. Emisja CO2 na osobę na kilometr dla samochodu wynosi dwadzieścia siedem, dwieście siedemdziesiąt jeden gramów. To są informacje. Czyli już się spójrzmy tutaj. O, tutaj mamy samochód, ma silnik, samochód jest pojazdem silnikowym. Czy samochód terenowy jest samochodem? Czy samochód ma nadwozie?A tu silnik elektryczny może czerpać energię z super, super kondensatora grafenowego. To jest ta różnica między grafem informacji, a grafem wiedzy. Jeszcze raz graf, graf wiedzy stosujemy do Big Picture i budowy struktury. Graf informacji stosujemy za to do budowy contentu. Mniej więcej takie są tutaj różnice. I krótkie podsumowanie tej lekcji wstępnej i przechodzimy do dalszych ćwiczeń. Każda strona internetowa, każda struktura strony internetowej to graf wiedzy. Bo Google jeżeli ma duży graf wiedzy, który opisuje całą wiedzę, strukturę i wszystkie połączenia, to tak też ekstrahuje naszą stronę i porównuje do istniejącej struktury w swoim wielkim grafie, czy naszej konkurencji w naszym kraju, tak? I każdy content, który macie na stronie internetowej czy Wasza konkurencja ma, to gra w informacji z perspektywy Google. Google tego poszukuje właśnie AI do AI Search, czy do AI Overview, do AI Mode, czyli informacje, które znajdują się w waszym contencie. Kto ma więcej, kto ma większe wypełnienia, ten jest bardziej atrakcyjny do brania udziału w syntezie AI. Dlatego też mówiłem o architektach wiedzy w poprzedniej lekcji. Na samym końcu pewnie tego tygodnia również to będziemy sobie podsumowywać na tym kierunku. No i wpiszcie sobie graf rack. Takich rozwiązań jest dosyć dużo. To jest jakby koncepcja Microsoftu, potwierdzająca te rzeczy, które wam powiedziałem. Tak, oni budują wiedzę. To jest dostępne na GitHubie. Mają prompty. To jest temat z zeszłego roku, natomiast jakby jest bardzo interesujący. Jak ktoś jest zainteresowany idźcie Microsoft Graph Rack. Poczytajcie jak Microsoft o tym myśli. Przypominam Microsoft jest właścicielem wyszukiwarki Bing. Bing wspiera czata GPT, więc pewnie też można sobie tam yyy po prostu poczytać, jak oni o tym myślą. To jest taka przykładowa wizualizacja właśnie z grafu ragu wiedzy i dzisiaj sobie zrobimy w kolejnych lekcjach nie taką samą, ale również fajną wizualizację. Także dzięki, dzięki za tą, za tą lekcję. Graf informacji, graf wiedzy. Przechodzimy do dalszych ćwiczeń. 