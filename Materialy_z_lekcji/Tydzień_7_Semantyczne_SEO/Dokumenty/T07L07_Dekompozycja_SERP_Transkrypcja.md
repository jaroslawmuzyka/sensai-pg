X. Okej, mamy kolejny krok. Szybkie przypomnienie mamy query expansion, czyli duży obrazek. Zebraliśmy i rozszerzyliśmy serpy klikając przez related keywords powiązane frazy tam do poziomu chyba stu dziewięćdziesięciu trzech fraz i zebraliśmy pięćset ponad z tych wyników unikalnych, co stanowi korpus wiedzowy do naszego grafu i dalszej topical mapy. Okej, kolejny, kolejny skrypt w tym samym collabie, który macie udostępniony to właśnie ta dekompozycja. Jezu, jak ja lubię to słowo. Znaczy no budowanie grafu wiedzy i teraz tak kilka rzeczy, co potrzebujemy. Dżina API no to już na pewno Damian Wam mówił o dżinie i pokazywał eee, na co chodzi, czyli po prostu ściąganie stron internetowych. To jest bardzo ciekawe. Zastosujemy dżinę, bo to jest dostępne dla Was wszystkich. Natomiast jeżeli wejdziecie po tygodniu z Danielem na poziom web codingu, sugeruję Wam napisać swój własny scraper, bo im bardziej dane będziecie mieli oczyszczone, tym bardziej uzyskacie lepsze efekty, tym będzie taniej i ogólnie polecam Wam napisać sobie swój albo albo ja tak sugeruję. Natomiast no możecie korzystać z dżiny. Po raz kolejny open router. Robimy to tylko i wyłącznie na flashu, bo to będzie tyle operacji, że, że jakbyśmy robili to na pro to pójdziemy z torbami, ale robimy to na flashu. Język polski. Ilość wątków dżiny dajmy na pięć. No ilość wątków open router no bo to będzie naprawdę dużo roboty, nawet dajmy powiedzmy, dajmy osiem wątków dżina i osiem albo nawet dziesięć, osiem albo dziesięć dobra i dziesięć wątków open router, żeby równolegle to zbudować w miarę w skończonym czasie. I zobaczcie z głębokości jeden uzyskaliśmy te pięćset sześćdziesiąt osiem adresów URL z głębokości dziesięć to pójdzie w tysiące, chyba nie wiem. No ale na pewno będziemy mieli cały obrazek danego konsensusu, kontekstu, na którym pracuje Google i zawsze w tym przypadku podajemy central entity. Dlaczego? Bo grafy zostaną stworzone na dwa sposoby. Dla jednego zapytania będą zawsze dwa grafy. Zobaczcie, bo tutaj macie akcesoria do samochodu, więc Wy potrzebujecie informacji o akcesoriach do samochodu i ten graf na podstawie tej strony w pierwszym kroku zostanie stworzony o akcesoriach do samochodu, żeby wiedzieć, co tam jest istotne do akcesoriach do samochodu. Natomiast my budujemy topical mapę w kontekście samochodów. Czyli musimy mieć dwa grafy, czyli ten opisujący akcesoria do samochodu jako akcesoria do samochodu i akcesoria do samochodu z perspektywy samochodu. Rozumiecie, o co chodzi? Albo na przykład jak powiedzmy jaki samochód kupić z perspektywy, jaki samochód kupić i tam będą detale i później musimy mieć dwie perspektywy w tym grafie, żeby to się później ładnie wyrysowało. Więc dlatego zawsze oceń. Określamy w tym przypadku central entity. Pokażę Wam to na wyniku, który zaraz uzyskamy. To jeszcze słowo komentarza. Ja zrobiłem między tymi skryptami następujące przejścia, żebyście mieli komplet danych. Tutaj się tworzą w Waszym obszarze roboczym pliki json. Czyli jakbyście chcieli sobie popodglądać. No to jest właśnie query expansion, które zostało zapisane, a w poprzednim ruchu robiliśmy sobie adresy URL, no to one też tutaj się znajdują, więc możecie sobie te pliki wynikowe podglądać. Ok, odpalamy, odpalamy skrypt i wracamy jak wykona się na podsumowanie. No dobra, mamy to. Chwilę to trwało. Wynik zapisany pomyślnie. Sprawdźmy sobie po prostu logi, co tutaj się wydarzyło, żebyśmy zrozumieli logikę przedsięwzięcia. Szanowni Państwo, no trochę się wydarzyło. Przeszliśmy przez tysiąc dwieście pięćdziesiąt jeden adresów URL. To trzeba podzielić na pół, bo tutaj były różne, różne operacje. Natomiast no ściągnęliśmy wszystkie możliwe te jednostki, treści powiązane i chciałem Wam pokazać bardzo ciekawą rzecz, bo tutaj zrobiłem Wam zarówno walidatory, jak i ponawianie. Zobaczcie. Za każdym razem sprawdzam dlatego Jason, dlatego zawsze Jason, bo jest łatwo go zwalidować. Że jest poprawny, żeby mieć spójność danych, bo cała gra właśnie o AI semantyk de facto też to jest spójność danych. I jeżeli nie ma spójności w danych i na przykład jest zły format, to zobaczcie. Odpowiedź nie jest poprawna. Jason, ponawianie druga próba i po drugiej próbie jest odpowiedź poprawna. To jest, nie wiem, czy mówiliśmy w tym kursie już o walidatorach, natomiast jakby jeżeli nie, to mówię, że AI, mimo że w skali, no potrafi się pomylić i takich niepoprawnych Jasonów otrzymaliśmy na takiej dużej próbie co prawda tylko sześć, więc jakby niezły wynik, ale ciągle, jeżeli będziemy skalować ten proces na tej głębokości dalekiej i tych adresów będą tysiące, no to, no to będzie sporo. Ja też ten prompt mam całkiem stabilny. Jeżeli prompt byłby napisane tak o no to tych niepoprawnych formatów byłoby znacznie więcej. Więc jakby system zakłada walidatory, walidatory również do dżiny, jeżeli coś się nie ściągnęło to próbuje ściągnąć trzy razy. Zazwyczaj jest zmieniony adres IP czy coś takiego. Plus ta dżina ma tutaj takie funkcje, jest skonfigurowana do tego, żeby była x Engine Browser. Tam jeszcze jest kilka innych opcji. Możecie sobie zobaczyć Markdown, więc to to, co potrzebujemy tą dżinę trzeba będzie oczyścić, ale tego już nie zrobiłem. No i okej, mamy to. Dane zostały zapisane i przyjrzyjmy się właśnie tutaj w kontekście tego central entity i query entity Knowledge Graph Output. Zobaczcie, to są nasze grafy wiedzy i przyjrzyjmy się tutaj sekundkę. No to jest ogromny plik tych grafów wiedzy mamy na pierwsze patrzenie mamy.Osiemdziesiąt trzy, bo tyle mieliśmy grup fraz kluczowych. Osiemdziesiąt trzy grupy po URL. Zgadza się. Natomiast tutaj mamy de facto dwa grafy w środku. To, co wam mówiłem, czyli query response, czyli graf wiedzy, query response. I tych grafów mamy właśnie osiemdziesiąt trzy i to są zawsze grafy dla rejestracja samochodu. Czyli widzimy source entity, rejestracja samochodu, relation wymaga target entity, wniosek o rejestrację pojazdu. Okej i rozważenie tematu rejestracji pojazdu. Jak sobie zejdziemy w dół- jest to jest drugi graf Entity response. Czyli mamy graf wyekstrachowany w kontekście rejestracji samochodów, ale też w kontekście samochodów. Czyli tam mieliśmy rejestrację samochodu, coś tam, a tutaj mamy samochód wymaga rejestracji pojazdu w drugą stronę, żeby ten graf dało się zwizualizować i żeby był kompletny i miał pełen obraz. Także de facto tych grafów mamy wygenerowanych osiemdziesiąt trzy, czyli osiemdziesiąt trzy razy dwa sto sześćdziesiąt sześć, sto sześćdziesiąt sześć. No i teraz tak tutaj na głębokości jeden powiedzmy, mamy no całkiem pokaźną reprezentację wiedzy w kontekście samochodów. Zaraz sobie to przejdziemy dalej. Natomiast jest sto sześćdziesiąt sześć grafów. My tego już nie zrobimy w czacie. Też nie jesteśmy w stanie tego w żaden sposób analizować. Nawet jakbyśmy poszli z tym do API, to, to jest po prostu zwyczajnie za dużo danych. Dlatego ok, tu sto sześćdziesiąt sześć grafów. Pełna reprezentacja, znaczy niepełna, ale na głębokości jeden, na głębokości dwadzieścia pewnie tych grafów będzie znacznie więcej, w kontekstu samochodów. Muszę Wam pokazać bazę danych grafowym, gdzie my to przejdziemy, gdzie my to zaindeksujemy, gdzie będziemy na tym operować. Tak więc podsumowanie: mamy zbudowaną reprezentację wiedzy do formy grafów, w kontekście Google Information Retrieval. No, no robimy to samo od początku. Gdzie jesteśmy? Powiedzmy query expansion, czyli Google sobie rozpisuje później ten SERP analysis. Czy to-- co do Google można porównać to do crawlowania indeksacji stron internetowych. My zrobiliśmy to samo tylko na istniejącym korpusie, a Google sam sobie ustala ten korpus. No i teraz zrobiliśmy ekstrakcję wiedzową, czyli my zrobiliśmy teraz ten proces information retrieval i tam Google ma features extraction. No to my to zrobiliśmy w tym momencie dokładnie to samo co Google. No i teraz jakby przeciągnąć dalej proces Google, to Google też musi mieć jakąś bazę grafową swoją. Musi, no bo musi. Po prostu musi ją mieć. Tak więc zapraszam do następnej lekcji. Zaczynamy od baz grafowych Neo4j. 