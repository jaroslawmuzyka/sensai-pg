Cześć! W poprzedniej lekcji dowiedzieliśmy się, czym są grafy wiedzy i grafy informacji, jaka jest różnica między nimi. Grafami informacji zajmujemy się w przyszłym tygodniu. Grafami wiedzy w tym tygodniu. Przykład samochodów z Wikipedii, który zrobiłem był minimalny. Było mało połączeń, mało encji powiązanych i ten graf był malutki, bo input danych, ilość danych przekazanych to była jedna strona Wikipedii, czyli zdecydowanie za mało. Tą lekcję chciałbym pokazać po to jako low hanging fruit, coś takiego prostego, co dosłownie może wykonać każdy. A już zaczniemy się zbliżać do jakichś struktur semantycznych topical map. Ciągle w mojej opinii ten deep research jest za małym, za małą strukturą, żeby porządnie zrobić mapę tematyczną, ale najszybszą możliwą, którą możecie zrobić za nie wiem ile ta lekcja będzie trwała, za piętnaście minut i to będzie Wam funkcjonować. O co chodzi? Skopiowanie jednej strony z Wikipedii to jest mało kontentu. Zrobienie deep researchu na przykładzie Gemini to pewnie będzie trzydzieści, czterdzieści stron A4 w kontekście po raz kolejny samochodów sobie zrobimy. Więc ten korpus danych wejściowych pewnie będzie znacznie, znacznie obszerniejszy, więcej encji, więcej połączeń, większa reprezentacja. Czyli możemy jakąś małą mapę tematyczną już sobie powoli na tej podstawie robić. Jak pamiętamy z nie wiem, czy pamiętacie, to przypomnę z pierwszego tygodnia, absolutnie najlepszy deep research na rynku to jest Gemini i tam zrobiłem analizę pod tą lekcję. W OpenAI jest taki sobie no, ale jest. Claude kilka tygodni temu wprowadziła do swojej oferty Deep Research, który jest całkiem, całkiem nieźle, chociaż nie daje aż takiej objętości. Bardzo dużo źródeł przeczyta, ale nie daje takiej objętości. Groq jest so so, ale Groq ma X-a, więc, więc jakby wiedzę aktualną z X-a. Jak jesteśmy w krypto, w stock-- jakiejś giełdzie, czy w polityce, to na pewno tam będzie najlepszy deep research. Ale chodźmy po kolei. Żeby zbudować graf wiedzy, potrzebujemy wsadu danowego. Zrobiliśmy deep research w kontekście samochodów. Kompleksowy, kompleksowy przewodnik. No i teraz tak, mamy graf wiedzy, czyli powiedzmy ten, ten prompt, który pokazywałem w poprzedniej lekcji. Zróbmy sobie z niego projekty. Zrobimy projekty zarówno w O3, jak i Gemini. Nie pokazywaliśmy gemów w Gemini w tym kursie, ale Wam pokażemy. Dobra, czyli zacznijmy sobie, żeby to jakoś układać i żebyście umieli zrobić takie grafy na podstawie deep researchu. Pierwsza sprawa możemy zrobić projekty. No i nazwijmy sobie projekt knowledge graph, niech będzie, nie? Czemu to jest spoko? Bo w czerwcu, na początku czerwca OpenAI wprowadziło możliwość wyboru, zdaje się większej ilości modeli, chyba wszystkich modeli do projektów, ale też większej ilości narzędzi do projektów. Więc jakby będziecie mieli jeden projekt, gdzie będzie wam budował tylko np. grafy wiedzy. Skopiujcie sobie ten prompt ode mnie. Ten prompt macie w plikach, dotąd. Bez central entity, bez grafu wiedzy. Dajemy go do instrukcji. No i teraz to będzie nasz projekt, który będzie nam budował grafy, grafy wiedzy w OpenAI. Gemy w Gemini. Ja lubię te modele googlowe. Poza tym jak budujemy semantykę, grafy wiedzy, topical mapy pod Google, trochę korzystając z modeli Google, no to pewnie jesteśmy trochę bliżej serduszka tak wprost. Więc jakby zrobimy sobie w Google. Tego nie pokazywaliśmy w pierwszych lekcjach, żeby zrobić taki projekt raczej coś a la GPT czy jakoś tam narzędzie. Klikamy sobie Explore gems i tutaj mamy new gem. No i tu mamy sytuację tożsamą, czyli wrzucanie wiedzy, wrzucanie instrukcji, nazwa, no i jakiś tam preview. Nazywamy go sobie knowledge graph. Skopiujemy sobie ten cały prompt, który Wam przygotowałem. Bez wiedzy. Zapisujemy. Uhu! I mamy naszego gema do budowania knowledge grafów. Ja uwielbiam ten model dwa i pół pro, więc jakby dlatego Gemini. Dobra, no okej. No to mamy, mamy nasze projekty, mamy nasze prompty już uzupełnione. No to bierzemy się za deep research. Weźmy to, skopiujmy wszystko. Export, copy content i chodźmy jeszcze chwileczkę do, do naszego promptu. Co my tutaj mieliśmy? Musimy określić właśnie ten seed entity, od którego wychodzimy i będziemy budować graf i język, w którym operujemy, czyli mamy powiedzmy samochód, mamy język polski. No i powiedzmy, skopiujmy to do OpenAI. I równolegle do Gemini. Jak ktoś lubi się bawić ustawieniami i wiemy, że analiza i ekstrakcja powinna być na zero, polecam jeszcze AI Studio. Więc jakby skopiujmy temperatura na zero sobie do AI Studio Model Pro Thinking Mode co do zasady będzie to bardzo, bardzo zbliżone. Natomiast jakby nie wszyscy lubią. AI Studio, co jest ciekawe, AI Studio jest za darmo, a Gemini potrzebuje subskrypcji. No ja mam szczęście, że jestem w tym pakiecie Google Workspace, więc mam. Natomiast jak nie macie Gemini możecie stosować AI Studio, to jest jakiś tam limit. Nie pamiętam, czy to jest miesięczny czy dzienny limit miliona tokenów, więc możecie sobie stosować zamiennie do tego. No dobra, no Gemini już nam buduje ten graf.O3 nam zbudowało ten graf. Natomiast widzicie, ten O3 nie jest jakby... To jest właśnie problem czat botów. Damian pewnie o tym mówił albo ja o tym mówiłem, że chat boty odpowiedzą Ci tak szybko, jak to możliwe i tak krótko, jak to możliwe, bo one są skonfigurowane do tego, żeby rozmawiać z Tobą. Więc ten graf, który otrzymaliśmy w poprzednim kroku z Open AI jest ciągle malutki. Natomiast graf z Gemini. Wygląda jak znacznie, znacznie, znacznie większy. Może nie jest jakoś fantastycznie duży, ale jest większy. A graf z-- o i tutaj to się dzieje, z AI Studio. Też, też, też to wielkie nie jest. I coś tutaj zwariował, bo nam napisał Jasona LD schemę orga. No nieważne. Mamy zbudowany graf wiedzy, czyli możemy stosować deep research w celu zbudowania grafu wiedzy, w tym, w tym przypadku w kontekście samochodu. Dalej sterując naszym promptem w tym miejscu, możemy go rozwijać cały czas na tym samym korpusie wsadowym. Samochód elektryczny, samochód jakiś tam, samochód jakiś tam. Oczywiście to pewnie by wymagało jakiegoś tam deep researchu w konkretnym kontekście, natomiast jakby to już się coś zaczyna budować. No i okej, pewnie tych grafów możemy zrobić kilka, czyli np. Deep Research z Google'a, Deep Research z Open AI, Deep Research Claude, Deep Research z czegoś tam, plus jeszcze ściągnąć strony internetowe, plus coś tam, zbudować grafów kilka. Polecam tutaj np. zrobić sobie kolejnego GEMa albo kolejnego, kolejny projekt, który będzie Wam sumował grafy do jednego. Albo prosty skrypt w Pythonie, który sumuje pięć Jasonów w jeden Jason. W ten sposób jedynie możemy rosnąć yyy grafami. Taka suma, kopiowanie grafów spowoduje dużą duplikację, więc pewnie trzeba by wyciągnąć duplikat, ale oczywiście możecie sobie stworzyć jeden, drugi, trzeci, czwarty, piąty, szósty, siódmy i próbować robić mapę tematyczną, do czego przechodzimy. Czyli podsumujemy. Deep Research jako źródło korpusu danowego, ekstrakcja do formy grafów i na podstawie grafów budowanie mapy tematycznej topical mapy, do której właśnie przechodzimy. Przygotowałem Wam bardzo prosty prompt do zabawy własnej przez Was, w celu budowania map tematycznych. Co tutaj jest istotnego? Ja zawsze utrzymuję wejście w tym samym formacie każdego grafu po to, żeby prompt czy AI doskonale rozumiało, co jest czym. Wchodzimy grafem, grafem wiedzy oraz centralną encją, wokół której budujemy mapę tematyczną. No bo tak jak Wam powiedziałem: seed, node, leaf i central entity i rozszerzanie, więc zawsze musimy wejść tą centralną encją, żeby rozszerzać ją. Encja po encji: samochód, samochód, motor, łódź. Po prostu sobie będziemy budować te mapy. W pierwszej lekcji mówiłem Wam o kilku rzeczach związanych z core section, czyli tą główną sekcją mapy tematycznej i outer, outer section, czyli tą, tą sekcją, taką rozbudowującą. Zaraz zobaczycie na przykładzie, co my tutaj będziemy, będziemy mieć. Możecie się wczytać w ten prompt. On jest udostępniony. Mówiąc o grafach, mówiłem o sile powiązań, czyli zobaczcie sobie. Zdefiniowaliśmy, że na przykład wszystko, co jest z siłą powiązania do samochodu, powiedzmy większym i równym osiemdziesiąt, to będzie core section. Wszystko, co jest z mniejszą siłą, to będzie outer section, no bo jest jakby takim uzupełnieniem mapy, mapy tematycznej. Oczywiście to są moje wartości, które przyjąłem po swoim uznaniu. Wy możecie przyjąć sobie inne, jeżeli chcecie mieć bardziej skupiony serwis, bardziej ekspercki w danym temacie i tylko pokrywać to w core section, to damy tu dziewięćdziesiąt, nie? Natomiast ja sobie takie wagi przyjąłem. Wchodzimy frazą kluczową, czyli nazwany keyword powinien być central entity i knowledge graphy. No, ale co do zasady no to sobie poradzi AI. No i modelem i językiem, językiem polskim. Dobra. Bierzemy ten prompt, znajduje się na GitHubie i w notatkach do lekcji. I po raz kolejny stworzymy sobie... No dobra, skopiujmy ten graf, to będzie nasza reprezentacja. Powiedzmy, na nim będziemy pracować. To jest ten graf. Dobra, on jest malutki, więc niewiele nam z tego wyjdzie. Idziemy do OpenAI i tworzymy sobie projekt. Projekt nazwiemy TopicalMap. Kupujemy prompt, który Wam przygotowałem. Dodaj instrukcje. Pamiętamy, że język polski jest tutaj w instrukcji. I czym my wchodzimy? Frazą główną, czyli tym central entity. Trzeba to zmienić w tym prompcie. Keyword, keyword niech będzie. To jest tylko zmienna, powiedzmy samochód. Knowledge graph. Powiedzmy, że to jest tyle. A, stwórzmy równolegle ten sam gem w Gemini. Explore gems. Knowledge graph. Topical map. Save. Let's go! Mamy topical mapę.No i bierzemy nasz input, czyli wchodzimy ten central entity, od którego będziemy rozpisywać temat. No i grafen, który jest w tym przypadku absolutnie mały. No i zobaczmy, jakie tematy nam się zaczną rozpisywać w kontekście, w kontekście samochodu. Jesteśmy! Wykonał nam się rezoning. Te topical mapy są malutkie, no bo też korpus danych był malutki i te grafy były malutkie, więc zobaczycie, jaką będziemy robić zaraz magię. Natomiast co mamy? To, co do tej pory nazywałem core section, outer section pewnie, bo ciężkie do, do wizualizacji. No ale powiedzmy mamy to, czyli sekcję główną, najważniejszą, najbardziej zbliżoną do encji rozpisującej opisującą encję. No i sekcję powiedzmy outer, czyli sekcję blog suplementacyjną czy tam rozwijającą. No i zobaczcie. Na podstawie grafu wiedzy, że wiemy, że samochód, definicja prawna i klasyfikacje to jest najważniejszy klaster tematyczny. No i tutaj mamy samochód jako pojazd mechaniczny. To już widzieliśmy na Wikipedii. To było pierwszy element grafu wiedzy, czyli po prostu opis samochodu, kryteria prędkości, wymogi rejestracji pojazdu, układ napędowy samochodu. To też widzieliśmy kilkukrotnie i podtematy, które tam są związane. Rola układu napędowego, silnik spalinowy, silnik elektryczny, czyli to są jakby ciągle opisywane przez listę sąsiedztwa. Czyli samochód zostanie opisany przez układ napędowy samochodu, który jest opisany przez silnik spalinowy, silnik elektryczny, silnik hybrydowy i tam kilka innych. Opisywany przez listę z sąsiedztwa. I to nam się zaczyna, zaczyna w tym momencie układać. Czy samochód opisany jako podwozie samochodowe i funkcje, konstrukcja podwozia czy nadwozie samochodu, czyli karoseria wygląd aerodynamiczny, przestrzeń pasażerska, strefa kontrolnego-- kontrolowanego zgniotu. I zobaczcie, to są wszystko tematy, które faktycznie opisują samochód, w tym core section. Teraz sobie pomyślcie o keyword research. Robicie sobie keyword research w temacie. Ok, zrobicie sobie klaseryzację czy nie? Zrobicie sobie embeddingi czy nie? Zrobicie sobie klaseryzację po serpie czy nie? To nie ma znaczenia. Ale robicie sobie keyword research. Jaka jest różnica między keyword research, a między tematami, encjami, konceptami i relacjami? No to sobie odpowiedzcie sami, bo w tym momencie jakby widzicie, jak to zaczyna się opisywać przez listę sąsiedztwa. Przyjrzyjmy się outer section, czyli to, co jest daleko od samochodu, jakby nie stanowi bezpośredniego sąsiedztwa. Znaczy, mm, stanowi, ale nie, nie jest w tym sile powiązania najbliżej, czyli outer section to, co może iść na bloga albo gdzieś dookoła samochodu, czyli wymogi formalno-prawne, proces rejestracji pojazdu, jakieś tam znaczenie progu prędkości konstrukcyjnej dwadzieścia pięć kilometrów. No nie jest to super istotne. Pewnie opisuje samochód, ale nie jest super istotne. Albo outer section analiza popularnych modeli. No i tam Corolla, Skoda Octavia. Mamy dwa modele, bo mieliśmy bardzo mały korpus. Znaczy ten graf był malutki. To jest jakby problem AI. Jak byśmy poszli na przykład do pewnie do Playgroundu czy bezpośrednio rozmawiali z Gemini dwa i pół Pro, to pewnie te grafy byłyby troszkę większe. Dlatego trzeba będzie je zwiększać. No i o to, o to, o to, o to w tym wszystkim chodzi. Czyli sekcję najbliższą opisującym temat i sekcję dalej opisującym temat szerzej. W ten sposób budując kontent możemy też czatować, jakie jest powiązanie? Zobaczcie, jakie jest-- tutaj będziemy robić już linkowanie wewnętrzne Contextual Bridge. W przyszłym tygodniu pewnie się zajmiemy tym troszeczkę szerzej. Jakie jest powiązanie pomiędzy samochodem a, o silnik spalinowy versus silnik elektryczny. Bardzo fajny artykuł. Powiedzmy, silnikiem spalinowym. Podaj mi kontekst relacji. No dobra, czyli na przykład mamy teraz artykuł o samochodach i chcemy zbudować właśnie ten contextual bridge, relacje, linkowanie wewnętrzne do silika, ee, spalinowego. I zobaczcie, to jest właśnie to, co wam mówiłem przy grafach wiedzy, czyli te relacje, te edge. Samochód has part ma część siła powiązania dziewięćdziesiąt pięć, czyli super istotna, no bo taka jest. Bez samochodu, bez silnika nie pojedzie. Silnik spalinowy. Kontekst grafu wiedzy. Silnik spalinowy jest jednym z podstawowych rozwiązań napędu stosowanego w samochodzie. Oznacza to, że silnik spalinowy występuje jako integralny element układu napędowego. To jest wszystko oczywiste. W pierwszej lekcji mówiłem o Bercie. Bert jest to model transformera Transformer, który czyta w lewą stronę, w prawą stronę. Więc jeżeli gdzieś przez przypadek umieścicie linkowanie wewnętrzne na temat silnika spalinowego w kontekście samochodu, to jest dobrze. Ale jeżeli umieścicie w tym kontekście, w którym się znajduje w grafie wiedzy bezpośrednio, a to jest jakby super logiczny kontekst, to Bert sobie przeczyta lewo, prawo, super zrozumie i zacznie ten graf rozbudowywać. Także czatując z tym dalej jesteście w stanie budować linkowanie wewnętrzne, struktury, zaproponuje mi strukturę adresu URL, zaproponuje mi coś tam. Bawcie się tym. Jeśli chodzi o Gemini, no to po raz kolejny ten graf był malutki, więc jakby nie przewidujemy rewelacji. Ale, ale mamy coś. Możecie sobie po prostu po kolei encje przetwarzać, budować, grafować i z tym czatować. I tutaj mamy definicje, kluczowe atrybuty samochodu. Samochód jako pojazd mechaniczny. Wymogi rejestracyjne w Polsce. Ok, czyli to jest jakby ta podstawowa część czy podstawowe komponenty. Budowa samochodu to też tam mieliśmy właśnie podwozie, fundamenty konstrukcyjne, nadwozie i powiedzmy w outer section tutaj brak danych w grafie wiedzy siła relacji osiemdziesiąt. No tak może być, bo ten graf był malutki albo, albo coś, coś coś ześwirował tutaj nam Gemini. No okej, to było takie poglądowe ćwiczenie. Czatujcie sobie z tym. Na przykład jaka jest relacja między tym, co wynika z tego, jakie są-- jest mały graf, więc jakby wiele nie dowiecie się, ale przynajmniej coś będziecie w stanie budować. Im te grafy będą większe, większe, większe, większe, tym więcej będziecie w stanie właśnie z tym reasoningiem sobie tutaj zrobić. I w sumie tyle. Jest to dosyć proste zastosowanie, ale bardzo skuteczne. Dużo lepsze niż keyword research, bo układa nam relacje właśnie, a wiemy, że wszystko to jest gra w informację, gra w wiedzę. No dobra, chodźmy do kolejnych lekcji. Tam pokażę wam profesjonalne zastosowania. Dzięki. 