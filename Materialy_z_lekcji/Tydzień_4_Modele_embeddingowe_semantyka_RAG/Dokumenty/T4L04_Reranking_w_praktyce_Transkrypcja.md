# Transkrypcja lekcji: Reranking w praktyce

Wiesz już z lekcji teoretycznej, że w procesie reagowym dość istotną rolę odgrywają modele rerankingowe. Wiesz też, że te modele rerankingowe odgrywają dość istotną rolę w uszeregowaniu rankingu wyszukiwarki Google. No i teraz w praktyce pokażę Ci, jak modele rerankingowe mogą zmienić istotę wyszukiwania względem modeli embeddingowych. Ponieważ w procesie reagowym najczęściej wyszukiwanie embeddingowe polega na tym, żeby wybrać grupę najbardziej zbliżonych. Natomiast modele rankingowe już z tych zbliżonych układają taki ranking ostateczny, bo mają trochę bardziej, bo są po prostu bardziej dokładne i wykorzystamy do tego ćwiczenia taki model rerankingowy od Giny. On jest wielojęzyczny i działa to mniej więcej po prostu w taki sposób, że wysyłamy mu zapytanie i treść dokumentów, które chcemy, żeby w tym zapytaniu były uwzględnione. No i on nam zwraca po prostu taki read advance score dla każdego z tych dokumentów, szeregując tam wyniki wyszukiwania.

Modeli relankingowych na rynku jest dość dużo. Kilka z nich umieszczę w GitHubie. Jest to między innymi firma Cohiri, która się tym specjalizuje. Ostatnio powstała też taka dystrybucja Colberta, która potrafi zarówno zamiać treści na embeddingi, ale też właśnie wykorzystuje relanking. Niestety Google oficjalnie żadnych modeli relankingowych nie udostępnia. Natomiast kukbuku Gemini znajdziesz też taką, powiedzmy, możliwość ustalenia re-rankingu w oparciu o modele Gemini, też Ci podlinkuję to w GitHubie, natomiast przejdziemy jak zwykle do notebooka Google Collab, który przygotowałem do tego, żeby zrozumieć ten proces, więc ten proces będzie przebiegał następująco.

Pobierzemy sobie treści adresów URL, które zawarte są we wskazanej przez mnie sitemapie, następnie te treści zamienimy na embeddingi za pomocą modelu embeddingowego od Google'a, text embedding 0307, Następnie dla każdego z adresów URL na podstawie jego tytułu dobierzemy jego 10 najbliższych sąsiadów, a następnie tych 10 sąsiadów najbliższych po prostu uszeregujemy ponownie za pomocą modelu relankingowego.

Wykorzystujemy tutaj znacznik title do tego, żeby porównywać embeddingi, natomiast możesz wykorzystać różne inne metody, żeby tego porównania dokonać. Często na przykład robię tak, że łączę title i description zamieniam na embeddingi. rzadko wykorzystuje cały content w embeddingach, ponieważ ten cały content, nawet jak go oczyścisz, on będzie zazwyczaj tak długi, że po prostu ten embedding nie będzie dokładny, ponieważ tak jak powiedziałem, tak długi tekst, model embeddingowy będzie starał się uśrednić do jednego wektora wielowymiarowego, co zazwyczaj kończy się tym, że różnica pomiędzy poszczególnymi tekstami, gdybym je porównywał, jest mała, chociaż logicznie jak patrzysz na to jest bardzo duża. I w rerankingu to wyjdzie, ale to pierwsze powiedzmy przetasowanie nie będzie po prostu dokładne, więc możemy też na przykład wykorzystać model językowy, żeby podsumował naszą treść i na podstawie tych podsumowań dokonać porównywań. Dlatego też właśnie też między innymi stosuje się czanki, czyli dzieli konten na kawałki, żeby to dopasowanie embeddingowe było bardziej skuteczne. Tutaj po prostu wykorzystamy znaczniki title. Zazwyczaj one wystarczają do tego, żeby wykonać wszystkie operacje na embeddingach, jeżeli chodzi o stronę internetową.

Więc dobrze, podaję tutaj stronę sitemapę do seum.com, sitemaps2.xml. Możesz podać swoją, pamiętaj tylko, żeby nie podawać zbyt dużej strony internetowej. Tutaj te skrypty nie były pisane po to, żeby przetwarzać duże zbiory danych. Nie chciałbym cię narazić na koszty. One poradzą sobie z dużym zbiorem danych, natomiast nie chciałbym, żeby był wysoki koszt.

Więc w pierwszym kroku podaję tutaj sitemapę, on sobie ją pobierze i pobierze za pomocą dżina, readera, treści ze strony internetowych i znacziki title. Możesz wykorzystać dowolny crawler, który wskazywaliśmy. Może to być Crow4AI, może być to Jina, może być to też coś innego, na przykład FireCrow.

Więc skrypt zaczął pracę. Znalazł 253 adresy URL w tej segmentie, więc dla 253 adresów URL pobierze sobie treść. Co prawda do pobrania samych znamcików title może Jina nie jest najlepszym wyborem, natomiast po prostu było to najprostsze jej zastosowanie. Ona też pobiera treść, więc gdybyście chcieli przerobić ten skrypt, na przykład pobawić się z tym, żeby podzielić te treści na czanki i tak dalej, to właśnie będą one też zapisane, więc można ją też do tego celu wykorzystać. Pobiera sobie tu, będziemy musieli poczekać na to 7 minut.

Nasz skrypt się wykonał, mamy już zapisane, powiedzmy, treści dla 253 adresów URL. One dostępne są tutaj w tym pliku, można je pobrać, przejrzeć. I teraz właśnie wykorzystamy modelem bendingowy od Google'a, żeby zamienić te tytuły na embeddingi. Tu wykorzystamy task type semantic similarity, bo takiego będziemy właśnie w celu używać tych embeddingów. Nie będziemy tu zapisywać niczego do bazy wektorowej, ponieważ tylko raz to przeliczamy. Tak jak powiedziałem, baza wektorowa ma sens wtedy, kiedy budujemy jakiś proces ragowy, który będziemy wykorzystywali w trybie ciągłym, albo chcemy wracać do jakichś informacji. W większości przypadków, jeżeli robimy coś raz, Możemy te embeddingi po prostu przejrzeć w pamięci maszyny, na której uruchamiamy ten skrypt.

Więc teraz przejdzie proces generowania embeddingu. No i nasze embeddingi się pobrały, zapisały w pliku. Możemy otworzyć ten plik, zobaczyć co tam już aktualnie się znajduje. Więc mamy nasz adres URL. Mamy pobrany znacik title. Niektórych tutaj się nie udało. mamy te embeddingi z modelu embeddingowego zapisane w takiej formie i status completed więc teraz obliczymy podobieństwo kosinusowe pomiędzy wszystkimi urlami czyli dla każdego urla wyznaczymy 10 jego najbliższych sąsiadów to będzie bardzo szybka operacja ok, już się zakończyła więc widzimy na przykład te 4 elementy audytu SEO, których zdarza się zapomnieć i to są najbliżsi sąsiedzi Podobieństwo tutaj wynosi 0,87, 0,83. To jest kilka przykładów oświetlonych, natomiast w pliku są wszystkie. Tu mamy na przykład AI w SEO i w marketingu, AI w marketingu, to my krótkie wykorzystanie CDGPT w podcaście. No i tak jak widzisz, tutaj mamy tych sąsiadów, natomiast ten, powiedzmy, podobieństwo, ono ma dość małą rozpiętość. To znaczy, że porusza się w takim dość małym zakresie. Tutaj mamy na przykład 0,89, a tu 0,86. takie bardzo różne artykuły, miały pewnie 0,6, natomiast to może nie być optymalne. I dlatego właśnie wykorzystujemy tutaj relanking.

Czyli on teraz weźmie te wszystkie wyniki, czyli dla każdego wyniku wyślemy 10 tytułów sąsiadów, których wyekstruktowaliśmy szybko za pomocą embeddingów i wyślemy do modelu relankingowego, żeby je uszeregował ponownie. 5 minut później. Nasz ranking się zakończy. Możemy zobaczyć teraz jak ten plik nasz wygląda. 11 MB. Więc mamy teraz dla każdego z adresów URL wybranych 10 najbliższych sąsiadów za pomocą embeddingu, a później za pomocą modelu re-rankingowego mamy tych 10 sąsiadów ułożonych ponownie. Tylko model re-rankingowy ma po prostu więcej kontekstu.

Jeszcze zrobiłem taki skrypt, który to porównuje, więc uruchommy go i zobaczmy, to tu jest, jakie są różnice. Zauważ, że rozpiętość ocen w przypadku modele mbedingowego wynosi między 0,84 a 0,88. W przypadku modelu rankingowego 0,36 a 0,71. Czyli to odchylenie standardowe wynosi 0,1 w przypadku modeli mbedingowych 0,013. Więc model embeddingowy nie jest tak bardzo dokładny jak model re-rankingowy. I tutaj bazowaliśmy na dość małej próbce 230 adresów URL, ale wyobraź sobie, że masz taki serwis, gdzie chcesz zbudować powiedzmy strukturę linkowania wewnętrznego no i on zabiera wiele tysięcy postont dość podobnych do siebie. Więc w przypadku embeddingów wybierałbym na przykład 100 najbardziej podobnych artykułów, a za pomocą modelu re-rankingowego z tych 100 schodziłbym na przykład do 10.

I tutaj tak jak widzisz różnica, na przykład mamy, nie wiem, co, copywriting, co to jest. I akurat powiedzmy wyniki są dość podobne, bo ten tekst akurat się dobrze, ten tekst ma bardzo dobrych sąsiadów, natomiast tutaj mamy na przykład wyniki już zupełnie inaczej wyglądają. I tutaj będzie to być może w przypadku wszystkich przykładów nie aż tak bardzo widoczne, Natomiast jak mamy dużą domenę z różnymi tematami, to te różnice pomiędzy re-rankingiem a embeddingami będą dość widoczne.

Zachęcam Cię do własnej eksploracji. Podlinkuję Ci jeszcze inne modele re-rankingowe w ramach GitHub'a. Możesz je przejrzeć, potestować, sprawdzić. Możesz ten proces uruchomić na swojej domenie i wyciągnąć własne wnioski. W kolejnych lekcjach będziemy ten cały proces ragowy składać do kupy. Przy okazji wyjaśniania jak działa AI Overviews i jak będzie działał AI Mode z Google. I z tej lekcji to wszystko. Zapraszam Cię do oglądania kolejnych. 