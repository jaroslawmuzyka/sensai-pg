W tej lekcji zajmiemy się rozwiązaniem, które nazywa się Supabase. Supabase posłuży nam w naszym kursie jako baza danych. Supabase to jest alternatywa dla rozwiązania Firebase, czyli to jest taki zestaw narzędzi, które pozwala tworzyć aplikacje takie backendowe. To znaczy, że oni dostarczają zestaw funkcji, które pozwolą ci na przykład stworzyć autentykację w swojej aplikacji, płatności, użytkowników i tak dalej. My to wykorzystamy w trochę innym celu, ponieważ Subabase jest świetną bazą danych do przetwarzania dużej ilości danych, ale jej dużą zaletą jest to, że pozwala też przetwarzać dane wektorowe. To znaczy, że będziemy mogli wykorzystywać tam modele embeddingowe, które będą bardzo istotne w tygodniu numer 4, więc dlatego to rozwiązanie akurat tutaj stosujemy. Subabase ostatnimi czasy zdobyła ogromną popularność, ponieważ w bardzo prosty sposób można za pomocą Subabase stworzyć aplikacje i szybko wypuścić ją na rynek. Tak naprawdę Supabase to jest baza danych Postgres, która ma taki interfejs webowy bardzo przyjazny dla użytkowników początkujących, więc jeżeli czujesz się na siłach, że jesteś w stanie administrować bazą danych, to możesz tak naprawdę wykorzystać bazę Postgres, zainstalować ją gdzieś i przy wykorzystaniu kilku dodatkowych dodatków uzyskać ten sam efekt. My po prostu wykorzystujemy Supabase, bo jest to prostsze. To, co jeszcze dostarcza Supabase i potencjalnie będziemy mogli wykorzystać, to są Edge Functions, czyli tu możemy po prostu za pomocą Supabase wykonywać różnego rodzaju skrypty. Na przykład, jeżeli użytkownik zrobi zapytanie na Twojej stronie wyszukiwarce, to możesz uruchomić jakąś funkcję, która przeszuka bazę danych i wyświetli wyniki przez API. Dzięki temu na swojej stronie będziesz mogła wyświetlić mu wyniki wyszukiwania, które są semantycznie dopasowane. Okej, to teraz pokażę jak Supabase wygląda. Stworzymy sobie bazę danych przy wykorzystaniu też modeli językowych i zaindeksujemy tam jakieś pierwsze informacje. To oczywiście będzie demonstracja. W kolejnych lekcjach i w kolejnych tygodniach będziemy w szerszym stopniu używać Supabase. Teraz chcemy po prostu zaznajomić się z tym interfejsem i zobaczyć jak on działa. Więc wchodzimy na stronę supabase.com. Jak widzimy tutaj wszystkie te funkcje, o których mówiłem są opisane. To, co nas interesuje w tym momencie, to jest właśnie Postgres Database i Vector. Vector tak naprawdę jest obsługiwany przez taki dodatek do Postgresa, który nazywa się PG Vector i udostępnia nam możliwość wyszukiwania wektorowego. Będziemy też poznawać inne bazy wektorowe w ramach kursu, więc to nie jest jedyne rozwiązanie, które do tego można zastosować. To, co jeszcze Subabase oferuje, to jest mnogość integracji, które możemy tutaj po prostu podłączyć, więc bardzo łatwo się z tym komunikować, ale też ta baza danych udostępnia bardzo proste API, więc jest bardzo łatwo chociażby napisać za pomocą takich rozwiązań jak kursor czy kodę, jakieś skrypty, które będą przetwarzały i umieszczały tam dane. Zacznę od tego, ile to kosztuje. Generalnie taki podstawowy, powiedzmy, pakiet, który spełni większość waszych oczekiwań jest po prostu za darmo. To znaczy mamy w nim nielimitowaną liczbę requestów do API, 50 tysięcy miesięcznie aktywnych użytkowników, akurat jeżeli nie będziesz tworzyć aplikacji w oparciu o Subabase, to nie jest to dla Ciebie interesujące. No i 500 megabajtów powierzchni dyskowej, co przy dużych zastosowaniach może być jakimś ograniczeniem, no i 5 gigabajtów przesyłu. Pakiet Pro za 25 dolarów jest wystarczający do dużo szerszych zastosowań. Ja akurat korzystam z tego za 25 dolarów i w zasadzie nie zbliżyłem się nawet do limitów. Dobrze, więc przejdziemy sobie do konta użytkownika i tutaj należy stworzyć nowy projekt na koncie użytkownika. Więc stworzymy nowy projekt. Najpierw tam trzeba też stworzyć organizację, czyli powiedzmy katalog dla naszych projektów, więc ja w swojej organizacji po prostu stworzę SEO QS, SEO 3.0. Tu wybieramy maszynę, na której będzie ta baza danych się opierać. W naszym przypadku wystarczy ta, która oznaczona jest jako mikro. My mamy to konto pro, więc każda kolejna taka instancja będzie kosztować 10 dolarów, natomiast w waszym przypadku nie jest to takie istotne. Wybieramy też region, na którym ta baza danych ma zostać uruchomiona, ponieważ możemy wybrać wiele. W naszym przypadku nie będzie miało to aż takiego znaczenia, ale gdybyśmy budowali powiedzmy aplikację dla użytkowników, no to miałoby to większe znaczenie. W tym przypadku wybiorę sobie Frankfurt, bo jest chyba najbliżej nas. Ok, i mamy tutaj nasz projekt Supabase, więc teraz zaznajomię Cię z tym tutaj, zaznajomię Cię z opcjami, które tu są dostępne, więc to co jest tutaj najważniejsze to jest database, a tu musimy chwilę poczekać, bo to jest setting up project. Musimy chwilę poczekać, aż ten projekt skończy się setupować. On teraz tworzy instancję Supabase właśnie na jakimś cloudzie w Frankfurcie. To może w międzyczasie... No i mamy nasz projekt uruchomiony w ramach Supabase. Mamy tutaj różne opcje. To co na początku musimy zrobić to stworzyć bazę danych do przechowywania naszych informacji. Tak jak widzisz tutaj nie ma żadnych tabel i jest tu też zakładka, która się nazywa extensions. To są takie dodatkowe elementy, które możemy doinstalować do tego Postgresa. I tu już pojawia się pierwsze rozszerzenie, które musimy dodać do listy naszych rozszerzeń, żebyśmy mogli przechowywać w bazie danych wektory. Czyli wyszukujemy tutaj rozszerzenie o nazwie wektor i włączamy je. Dzięki temu będziemy mogli tworzyć kolumny zawierające wektory. My będziemy akurat w większości przypadków wykorzystywać skrypty Python do generowania embeddingów i zapisywać wektory w bazie danych Supabase, ale Superbase można też tak skonfigurować, że w momencie, kiedy coś do bazy danych zostanie dodane, to od razu też zostanie zamienione na embeddingi, więc tutaj są różne opcje współpracy z tą bazą danych. Więc mamy już wszystkie dodatki, których będziemy do tej lekcji potrzebowali, więc teraz przychodzi czas, że trzeba stworzyć bazę danych. I akurat my stworzymy sobie przykładową bazę danych na bazie informacji z Senuto. Więc wyszukam sobie domenę senuto i pobiorę jakiś raport, który zapiszę do pliku Excel. Zapisałem tutaj plik Excel, który chciałbym, żeby przechowywany został w tej bazie danych. Oczywiście to jest ćwiczenie, tak praktycznie nie ma sensu przechowywać plików w Excel w bazie danych, ale potem na bazie tych danych, które tutaj zaimportujemy, będziemy dokonywać różnych operacji, m.in. np. pobierać metadescription, tytuł, zamieniać to na embeddingi i porównywać, czy nasze tytuły są dobrze zortymalizowane dla słów kluczowych, które widoczne są w Senuto. I tutaj przejdziemy sobie do modelu językowego, bo jak zapewne wiesz, to tutaj, żeby stworzyć bazę danych, czy tabelę w bazie danych, musielibyśmy skorzystać z SQL-a, bo Postgres SQL to jest baza danych, która wykorzystuje składnie języka SQL. Natomiast robimy ten kurs z założeniem, że nie umiesz posługiwać się SQL-em, więc prawdopodobnie kod, który będzie odpowiedzialny za wygenerowanie tabel w bazie danych, będziesz tworzyć za pomocą modelu językowego, więc z takim założeniem to robimy. Natomiast zachęcam, żeby nauczyć się podstaw SQL-a, bo one się bardzo przydają. I baza danych też jest potrzebna dlatego, że nie jesteśmy w stanie obsłużyć wszystkiego Google Sheets i Excel-u, ponieważ to są rozwiązania, które są dość nieskalowalne, mają swoje ograniczenia, natomiast baza danych jest w stanie przechować znacznie więcej informacji, ale też Superbase pozwala na wyszukiwanie informacji i to jest dla nas kluczowe. Więc mam tutaj, wykorzystam do tego celu Clodę i model Clod Sonnet 3.7 i wgram mu tutaj ten plik. OK. I napiszemy, wgrywam. Dziękuje za oglądanie. Dzięki za oglądanie! Tutaj już wyjaśnię, że w promptie napisałem, że ta tabela będzie przechowywać też wektor z 3772 wymiarami, ponieważ już wiem, że będę używał takiego modelu embeddingowego, który w tylu wymiarach zapisuje wektory. W pewnym razie nie musisz tego rozumieć. Chodzi po prostu o to, żeby przygotować już tą bazę danych do tego, żeby mogła nam w przyszłości posłużyć. Tutaj jeszcze powiem modelowi językowemu, że nie każdy wiersz w tabeli master musi mieć URL. I on powinien teraz sobie napisać skrypt, który przeanalizuje ten plik Excel i napisać mi kwerendę do SQL, która wygeneruje mi te odpowiednie tabele. Jak później będziesz pracował z modelami językowymi w ramach tego kursu, dowiesz się jak optymalizować tabelę, jak optymalizować bazę danych za pomocą indeksów i dodatkowych optymalizacji. Na razie chcemy stworzyć po prostu tabelę, która będzie przechowywała te informacje, które pobraliśmy sobie z Senuto. Oczywiście mógłbym pobrać te dane z Senuto przez API i zapisać je tam, dokonać na nich operacji itd. To też będziemy robili. więc na razie to jest taki proces, żeby po prostu zaprezentować jak to wszystko działa i po prostu po kolei budować u Ciebie dodatkowe umiejętności. To akurat wykorzystuję Clode 3.7 SONET natomiast świetnie się tu też sprawdzi Gemini 2.5 Pro, Gemini 2.5 Flash i prawdopodobnie też inne modele, które są dostępne na rynku. Mógłbym to też zrobić w kursorze czy Winserfie, natomiast jak na razie nie poznałem się jeszcze tych narzędzi w ramach tego kursu, to korzystamy z tego, co już było pokazywane w poprzednich tygodniach. Tutaj pisze właśnie nam zapytania do bazy danych. Tak jak widzisz, on też określa dokładnie jakie typy kolumn w bazie danych mają zostać stworzone i tak dalej. Więc to, co musimy zrobić, to po prostu skopiować te, serendy i przejść tutaj do zakładki SQL Editor i wkleić te serendy i to co powinno się wydarzyć, to powinniśmy utworzyć właśnie, o tutaj dostaliśmy jakiś dodatkowy error, więc wrócimy do Clode i wstawimy mu ten error, on powinien poprawić te zapytania. chodzi tu po prostu o to, że Supa Base nie przewidziała, że będziemy mieli tyle wymiarów z jakiegoś powodu chociaż powinno to działać, zaraz zobaczymy 1536 ok, no Klaudę tutaj nam sugeruje, że powinniśmy mieć 2000 wymiarów, ja wiem z góry, że będę potrzebował 3072 więc musi zmienić definicję tej kolumny, więc jeszcze raz sobie kopiłem, ja też udostępnię w materiałach dodatkowych tą dyskusję z Klaudę będziesz mogła ją otworzyć i po prostu prześledzić co ja tutaj robiłem spróbujmy jeszcze raz to wkleić no i jest sukces no rows returned czyli teraz jak wejdziemy sobie do table editor powinniśmy mieć tabelę master data i url data i to co jest bardzo istotne no to teraz chcemy się chcemy chcemy się skomunikować z tą tabelą za pomocą API i tu jest coś takiego jak RLS Policies, to znaczy to są takie polisy w postgresie, które mówią o tym, kto konkretnie może się połączyć z bazą danych i w jaki sposób, więc musimy taką polisę dla taką polisę po prostu stworzyć i stworzymy, żeby z API mógł się komunikować użytkownik Anon i prawdopodobnie nie powinieneś, nie powinnaś tak robić w swoich projektach, ponieważ wtedy każdy, kto ma klucz API do tabeli bazie danych, będzie mógł tam wrzucić dane, pobrać dane i tak dalej, więc tutaj, jeżeli robisz jakiś projekt produkcyjny, to warto zadbać o to, żeby te polisy były ustawione w lepszy sposób, więc na razie włączamy te polisy RLS do drugiej tabeli również. I teraz wracamy do Clode i prosimy go To ustawiamy tylko raz do każdej tabeli ok, więc kopiujemy to co tutaj dostaliśmy komentarze też możemy skopiować przechodzimy do SQL Editor i wklejamy te zapytania i tutaj mamy sukces jak wejdziemy sobie teraz do Table Editor i do Out Policies, to powinniśmy widzieć, jakie policy tutaj są. To, co jest jeszcze tutaj w Superbase dostępne, to oni mają takiego swojego wewnętrznego asystenta, więc można go tutaj zawsze wywołać i poprosić go, żeby on stworzył te policy. Nie musimy korzystać z Clode, więc jeżeli chcesz wiedzieć, jak działa jakaś konkretna funkcja w Superbase, to wystarczy, że skorzystamy z tego asystenta i on nam wszystko podpowie. Okej, no to teraz czas, żeby wrzucić dane do tych tabel. Te tabele są połączone przez URL ID i tutaj ID, więc pomiędzy nimi jest komunikacja. To, co jest istotne, moglibyśmy insertować te dane ręcznie, insertować kolumny, ale też importować z CSV. No i ja te dane mam w CSV, natomiast napiszemy skrypt Pythona, który po prostu zrobi to za nas. Więc wrócimy do Cloudem i poprosimy o to, żeby... Proszę go, żeby uwzględnił zmienny na superbase.url i superbase.ap.key, bo ponieważ pobierzemy to zaraz w ustawień konta, pamiętaj o zmapowaniu pól z języka polskiego. Ponieważ my mieliśmy Excela z nazwami kolumn polskich, on nam stworzył tabelę z nazwami kolumn angielskich i zazwyczaj lepiej tworzyć wszystkie kolumny w języku angielskim, to poproszę go, żeby też w tym skrypcie Python przewidział zmapowanie pól z języka polskiego na angielski. Zapomniałem powiedzieć mu, żeby jeszcze przewidział pole na plik, który mam, ale zaraz to poprawimy. Ok, przechodzimy do Google Colab, wklejam ten skrypt, który trochę zaadaptowałem i on tutaj zaraz powinien nas zapytać o plik, który chcemy zaimportować, więc wybieram ten plik, który wcześniej przygotowałem. Pyta mnie tutaj teraz, czy chcę zaimportować te dane do Supabase. Więc zaimportowano. Importuje on po 50 adresów URL w jednym zapytaniu. Więc możemy już przejść do Supabase i zobaczyć, czy te dane tam trafiają. Więc najpierw URL data, jak widać dane się pojawiły. I za chwilę on skończy to importowanie i będziemy mogli w pełni przeglądać te dane. więc za chwilę przejdziemy do Subabase i to przejrzymy. Uruchomiliśmy ten skrypt w Google Collab, on już importuje tutaj te dane. Jak zobaczysz konwersację z Klodem, to zobaczysz, że tam kilka razy podejmowałem próby wygenerowania tego skryptu. No tak wygląda praca z modelami językowymi, więc tak to już działa. Natomiast udało się to ostatecznie, więc jeżeli będziesz korzystać z tych skryptów, to skorzystaj z tego, które się znajduje w Google Colabie, żebyśmy mieli pewność, że wszystko działa poprawnie. Więc wracamy sobie do Supabase. Mamy te dane już tej tabeli, mamy dane z urlami. Później będziemy wykorzystywać tą tabelę z urlami, żeby pobierać tytuły, description, zamieniać się na wektory i porównywać ze słowami kluczowymi. Natomiast na razie się tym nie zajmujemy. I w ramach tych tabel mamy coś takiego jak SQL Editor i tutaj możemy odpytywać te tabele, więc możemy sami napisać jakieś zapytanie master data czyli na przykład mogę z tej tabeli wybrać wszystkie słowa kluczowe, które są na pozycji mniejszej lub równej 10 mogę na przykład też wszystkie, które zawierają SEO a, to jest błąd i bardzo szybko przeszukiwać te dane. Natomiast tak jak widać to wymaga zdolności pisania zapytania z QL, więc żeby sprawdzić co my tak naprawdę w tej tabeli mamy to możemy użyć takiego zapytania, je też wkleję do materiałów dodatkowych i możemy to skopiować jako JSON i tutaj poprosić LMA ... jasonie konstrukcję tabeli, jaką mam i on powinien wygenerować zapytanie SQL, które spełni to zadanie. Więc kopiujemy to zapytanie i wklejamy je tutaj. No i otrzymujemy to, co chcieliśmy. Więc tak możemy po prostu zautomatyzować cały ten proces. Więc w tym, w tej konkretnej lekcji poznałaś, czym jest Superbase. Wrzuciliśmy tu swoje pierwsze dane za pomocą Kryptu Python przez API Superbase, więc to jest dobra podstawa do tego, żeby dalej się tu rozwijać. Będziemy korzystać z Superbase w kolejnych lekcjach, więc zapoznaj się z tym interfejsem, z tą bazą danych. Jeśli możesz, to połócz się podstaw SQL-a. Wrzucę też materiały dodatkowe, które mogą w tym pomóc i kilka dodatkowych materiałów na GitHub-ie, więc sprawdź tam sekcję, bo jest kilka dodatkowych informacji. Do zobaczenia w kolejnej lekcji.