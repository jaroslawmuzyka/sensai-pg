# T8L05: Tworzenie treści z AI - Budowa bazy wiedzy (RAG) - Transkrypcja

**Tydzień:** 8  
**Lekcja:** 05  
**Temat:** Tworzenie treści z AI - Budowa bazy wiedzy (RAG)  
**Link do lekcji:** [SensAI Academy](https://learn.sensai.academy/next/public/lesson/352)

---

## Transkrypcja lekcji

Cześć, witam Cię na kolejnym kroku. Krok po kroczku dochodzimy do generowania kontentu. Jak widzisz, to nie mogło być takie na zasadzie hej, czat GPT, napisz mi artykuł na temat, chociaż takie porady również słyszałem, że istnieją na rynku i to w branży SEO. Teraz zbudujemy sobie RAG, czyli ten Retrieval Augmented Generation, o którym zarówno mówił Damian Sałkowski. Ja też mówiłem we wstępie do tego tygodnia. Czyli będziemy sobie dzielić tak jak wyszukiwarka wiedzę z danych artykułów czy wiedzy internetowej na krótkie jednostki treści, które w kolejnych krokach będziemy zasilać do generowania konkretnych nagłówków, tak żeby były one jak najbardziej faktyczne i unikniemy dzięki temu absolutnie procesu-- znaczy absolutnie, w bardzo wysokim prawdopodobieństwie procesu halucynacji modeli językowych. No i jeżeli będziemy na przykład reoptymalizować kontent w przyszłości, ponawiając proces budowania właśnie tej wiedzy i data chunkingu, będziemy w stanie jakby kontent odświeżać, ale to jest future, skupmy się na podstawach. Okej, pierwsza sprawa Retrieval Augmented Generation: dobieranie najlepiej dopasowanych fragmentów do danych nagłówków w celu ich generacji, zasilenia faktycznymi informacjami. Data chunking: wyciąganie informacji z na przykład z Google. Po kolei, mam dla Was przygotowane procesy i pójdziemy sobie tym samym, tym samym torem. Zobaczcie to, co będzie nam potrzebne, to będzie właśnie nagłówki do generacji, co do zasady, czyli uznaliśmy, że te nagłówki będą najlepsze. Oczywiście załóżmy, że ja już je sobie w tym momencie zmoderowałem. Damy to trochę szersze, żeby lepiej mieć na to optykę i na tej podstawie będziemy sobie chcieli przede wszystkim w tym procesie budowania RAG-u na każdy z tych nagłówek odpowiedzieć wiedzowo, czyli bezpośrednio zapytać-- może tak: zbudować wiedzę w kontekście kortyzolu jeszcze raz. Nie będziemy wykorzystywać tej, którą mamy, bo, bo tutaj będziemy chcieli, żeby AI odpowiedziała nam na te konkretne pytania, które są w nagłówkach, czy też odpowiedziała na nasze konkretne nagłówki. Jeżeli byśmy mieli np. nagłówki rozbudowane, to też pasuje na nie odpowiedzieć i damy zadanie sztucznej inteligencji, żeby sama zdecydowała, na jakie pytania chce odpowiedzieć, czy jakie pytanie można zadać na podstawie korpusu wiedzowego. Po co taki podział? Zaraz go jeszcze pokażę. Po to, że ja uważam, że w procesie RAG-u czy data chunkingu-- data chunkingu de facto, bo jesteśmy przy tym. Wiedzę można podzielić na dwa, dwa typy: wiedzę dokładną, czyli bezpośrednio dopasowaną, co to jest kortyzol? Kortyzol jest to i wiedzę, powiedzmy ogólną, czyli która nie istnieje w danej chwili w naszym zestawie nagłówków, ale bezpośrednio odnosi się do tematu i model językowy uznał, że ona jest jakby istotna, to nam bardzo fajnie dopełni procesu jakby generacji treści, bo mogliśmy czegoś nie przewidzieć, a akurat nam to dopełni pełnego obrazu i kontekstu, bo cały czas się poruszamy wokół kontekstu kortyzolu. Jeśli chodzi o data chunking istnieje bardzo dużo technik. Ja akurat stosuję w tym procesie taką, która będzie nam odpowiadała zarówno na te właśnie pytania, jak powiedziałem i sama zdecyduję, na jakie pytanie odpowiedzieć. Innym skutecznym procesem jest to, żeby na przykład odpowiedzieć na pytanie bardzo krótko, zwięźle, a w drugim kroku odpowiedzieć bardzo długą formą, czyli na koniec dnia sztuczna inteligencja w procesie Retrieval Augmented Generation dostanie dwie informacje: bardzo krótką, bardzo konkretną i bardzo długą, bardzo wyczerpującą dany temat. To też jest skuteczna metoda data chunkingu. No ale chodźmy po kolei. Oczywiście przygotowałem dla Was na to osobny workflow, który sobie zaraz zautomatyzujemy. Pokrótce omówię jego strukturę. Pierwsza sprawa: idziemy do Google, będziemy ponownie przeszukiwać internet. Wiem, że już to raz robiliśmy, natomiast tam mieliśmy zupełnie inne zadania, tam jeszcze nie mieliśmy nagłówków, więc nie mogliśmy robić data chunkingu. Generowaliśmy graf wiedzy, graf informacji. Pewnie można by użyć ich do zbudowania Retrieval Augmented Generation, ale w kolejnym kroku dowiecie się, czemu tego nie używam jeszcze teraz. Idziemy do wyszukiwarki. Po raz kolejny przeszukamy sobie Google AI Overview. Weźmiemy strony internetowe i top dziesięć wyników. Po raz kolejny usuniemy brandy. Nie będę omawiać dlaczego. Mówiłem już. Nie chcemy mieć w naszej wiedzy informacji o tym, że na przykład Allegro jest Allegro i będziemy chodzić po tych stronach internetowych. Ja w procesie znacznie go przyśpieszam do sześciu, sześciu, sześciu wątków i odpowiemy sobie właśnie na te pytania dokładne, czyli uznamy, że to są nasze pytania i do każdego nagłówka odpiszemy odpowiedź wiedzową bezpośrednio. Czemu tak? Bo wtedy Google najlepiej nam-- nie Google, tylko AI nam najlepiej dopasuje te fragmenty. A w kolejnym kroku pozwolimy sztucznej inteligencji, jakbyśmy spojrzeli na prompt, zaraz zobaczycie różnicę. To jest prompt, który właśnie mówi nam, że będzie chunkował content, czyli to, co nam potrzebne na potrzeby RAG-u. Zaraz zobaczycie, czemu akurat w ten sposób. To set all possible questions and answers, czyli dajmy mu dowolność, żeby on sam zdecydował, jakie pytania sobie zada i na nie odpowie. Możliwość go w jakiś sposób nie przewidzieć. Albo to będzie kontekst uzupełniający dla nas. Each chunk should focus on main topic and be on more than two hundred-- four hundred tokens. Czemu four hundred? Microsoft stosuje pięćset, ja też będę stosował pięćset, ale jeśli podajemy jakąś liczbę to zazwyczaj to się nie udaje, więc ja daję czterysta, on i tak mi wyjdzie jak testowałem na czterysta pięćdziesiąt, czterysta siedemdziesiąt. Czyli jesteśmy blisko Microsoftu. To żeby było nie za długie po prostu, bo tak będziemy nasycać i tyle to mniej więcej wyjdzie. Możemy sobie to zaraz przetrenować ile to wychodzi.No i oczywiście wstepy, czyli cały czas podróżujemy wokół tego samego tematu. Cały czas w języku usuwamy brandy. No i odpowiedzi na pytania, odpowiedzi na pytania. Co ważnego z separatorem? Niedługo się dowiecie, dlaczego taki separator mu wprowadzam. No i oczywiście jakiś tam przykład odpowiedzi, że ma być odpowiedź, ma być pytanie, odpowiedź, separator, pytanie, odpowiedź, separator, pytanie i separator. I tak w kółko. No i to są pytania ogólne. Natomiast zobaczmy różnice do pytań dokładnych. Tu jest prompt dotyczący pytań dokładnych. On jest troszeczkę bardziej rozbudowany, bo ma być po prostu dokładniejszy. Tamten srowy jest puszczony. Gdzie ja to mam? You are the expert content analyst asked to change and structure information from your goal is to create a set of headings knowledge based on contact provided for all this instruction. Czyli ja mam to w tym userze. Jest to, Jest to. Widzicie, tam nie przesyłam mu informacji dotyczących żadnych pytań. W tym przypadku przesyłam mu listę moich nagłówków po prostu. Czyli here is a list of heading to build knowledge for based on the content and heading to answer. Czyli musi mi odpowiedzieć na te konkretne headingi w sposób zwięzły. To jest ta różnica i ten answer tu się pojawi. Tutaj given answer, ask question, ok. No dobra, tak, na tym polega różnica. Zacznijmy ten proces. Żeby to rozpocząć, odświeżymy oczywiście, zapiszę, żeby mieć pewność, że pracujemy na tej samej wersji cały czas. Zobaczcie, zaraz będziemy automatyzować. Żeby rozpocząć proces potrzebujemy keyworda, języku, w którym się poruszamy i headingów, na które będziemy udzielać odpowiedzi. Ale oczywiście też dostaniemy odpowiedzi ogólne, czyli po kolei. Co to jest kortyzol? Polish i headingi mamy te, które wybraliśmy. Powiedzmy to są nasze nagłówki do generacji. No i zobaczcie, co się dzieje po kolei. To będzie bardzo szybki proces. Raz jest wyszukiwanie, to już widzieliśmy ekstrakcję brandów, zaraz nastąpi przeszukiwanie stron internetowych. Czyli wiemy, że tutaj jest siedemnaście stron internetowych, unikalnych z overview i sto dziesięć wyników. Czyli widzicie top dziesięć stron, dziesięć stron w wynikach i siedem stron w overview unikalnych. Ciekawa informacja. Jak akurat wygląda ten serw? No i zacznie zaraz nam odpowiadać na te pytania. Teraz zróbmy krótką przerwę. Wracamy jak proces będzie skończony. Dobra, jesteśmy. Proces co prawda jeszcze trwa, ale już widzimy pierwsze wyniki. Czyli widzimy te pytania, które mieliśmy. Co to jest kortyzol? Czyli oczywiście jest to nasz oczywiście nasz pierwszy, pierwszy nagłówek. Dalej będzie: jakie funkcje pełni kortyzol w organizmie? Oczywiście to jest już kolejny nagłówek. Tak więc uzyskujemy już te odpowiedzi, którymi będziemy zasilać nasz retrieval augmented generation. To są wszystkie informacje o kortyzolu w formie pisanej, które dalej będziemy podawać do, do, mmm-- w procesie generacji, który będziemy robili już niedługo. I zobaczcie ten, powiedzmy, ten fragment wydaje się być całkiem obszerny i jak sobie wejdziemy na Open Tokenizer, to zobaczycie, że to jest właśnie te pewnie około poniżej pięciuset tokenów. Oczywiście ja robiłem to na innym modelu, no ale czterysta trzydzieści jeden tokenów, czyli, czyli po prostu jesteśmy zgodnie, zgodnie z instrukcją systemową. Ok, no to mamy to, skopiujmy sobie to do naszego notatnika. I co tu się wydarzyło? To są właśnie te separatory, które chciałem. Zobaczcie, mamy, mamy pytanie, taki format. Mamy odpowiedź na to pytanie. Czyli nasz mamy nagłówek, pytanie, hashtag, czyli separator. No i tu są te główne odpowiedzi na najważniejsze nasze pytania. One są najbardziej docięte, a tutaj poluźniliśmy sztucznej inteligencji, żeby nam, żeby nam podała wszystkie jakby możliwości dookoła. Dlatego ten prompt był dużo prostszy. Czy kortyzol jest szkodliwy? No nie? Takie pytanie nam zadał automatycznie. Jeżeli chodzi o nasz content plan. Widzicie, nie ma tego, ale to jest fajny kontekst uzupełniający nasz docelowy artykuł, prawda? A tu jest wyczerpanie tematu w formie widzicie różnicę nawet w długościach. Tutaj go spuściliśmy ze smyczy. Powiedzmy daliśmy mu luz, żeby nam zrobił wypełnienie tematyczne dookoła. A tutaj mamy jakby dociętą, konkretną odpowiedź, której oczekujemy w naszym artykule. No dobra, co my z tym możemy zrobić? Przede wszystkim pokażę wam, jak zbudować rag tak ręcznie i zaraz sobie zautomatyzujemy ten proces ragowy. Czyli to jest powiedzmy nasz wynik z procesu. Zapiszemy go sobie jako na moim dysku, powiedzmy kortyzol rag txt. Chodźcie, pokażę wam jak, jak zbudować raga ręcznie i zaraz będziemy sobie go automatyzować, żeby każdy z was miał go automatycznie. Zobaczcie, tutaj znajduje się przycisk Wiedza. Tam jeszcze nie byliśmy, nie doszliśmy tam, ale w tym momencie już jakby wchodzimy do wiedzy, mamy możliwość utworzenia nowej wiedzy, dostępu do API. Tam zaraz będziemy właśnie wchodzić i automatyzować proces budowania tej wiedzy. Tutaj mamy możliwość podpinania zewnętrznych, zewnętrznych interfejsów wiedzowych, nie będziemy się tym zajmować w tych ćwiczeniach. Natomiast informuję, że możemy tutaj się wpinać do zewnętrznych czy jakichś grafowych, graf ragów, light ragów czy innych historii.To jest bardzo, bardzo interesujące dla osób zaawansowanych, że takie możliwości są, żeby wpiąć zewnętrzne systemy wiedzowe. No dobra, klikamy utwórz wiedzę. Będziemy mieli kilka możliwości. Import z pliku tekstowego, czyli to, co my zrobimy Import z Notion. Jeśli mamy jakąś na przykład bazę wiedzy wewnętrznej, synchronizacja strony internetowej zdaje się z wykorzystaniem Fire Crowla albo Giny Readera, albo jakiegoś Water Crowla, którego jeszcze nie miałem przyjemności używać. W sensie każdą stronę internetową możemy zmienić na RAG, ale ale, ale to nie jest to co my chcemy, bo my mamy fajny proces, który nam wiedzę zbudował. Co to tutaj robimy? Klikamy import z pliku tekstowego. Przeglądamy, co my tutaj mamy. Mamy ten kortyzol rag no i wgrywamy i powiedzmy się, zaraz ta wiedza nam zbuduje. Zobaczcie, mamy separator bloków, tutaj mamy znaki nowej linii. A jaki my mamy separator? My mamy hashtagi. No to hashtagi wrzucamy. Maksymalna długość bloku. Jaka była? Zobaczcie, tutaj są znaki, o tutaj znaki ostatnio ode mnie chciał tokeny. No dobra, czyli jak chcę dwa tysiące tysiąc czterdzieści dwa tysiące czterdzieści cztery znaki tam tokenizer. Dobra, dajmy mu więcej, bo to w języku polskim nie wiadomo ile wyjdzie. Nakładka bloków, to i tak będziemy określać zaraz sobie w API metryką, więc jakby ok. Zastąp kolejne spacje nowymi liniami to bla. Ok, spacje zastąpimy. Usuń wszystkie adresy URL, ma funkcję, że Wam wyczyści to, ale my tego nie potrzebujemy. Tutaj masz jeszcze kilka innych funkcji, których my nie potrzebujemy. No i mamy jakby nasze chunki, czyli właśnie te elementy. Google robi dokładnie to samo. Tak samo, tak samo sobie chunkuje wiedzę i tak samo nawet w snippetach AI Overview to, co wam pokazywałem na samym początku, są właśnie te chunki, czyli pytanie-odpowiedź-pytanie-odpowiedź-pytanie-odpowiedź. No i mamy podzieloną naszą bazę wiedzy. Pokażę Wam kilka kluczowych tutaj opcji konfiguracyjnych. Pierwsza sprawa wysoka jakość. To jest na tyle tanie, że robimy zawsze wysoką jakość. Chyba, że ten rak będzie gigantyczny, to może wtedy faktycznie ekonomicznie. Ale raczej, raczej wysoką jakość. Ewentualnie możemy zasterować sobie tutaj mniejszym modelem, jeżeli będziemy mieli ogromną ilość danych, mieć po prostu small. No ale my mamy mało danych, więc dajemy large. I tutaj mamy kilka typów wyszukiwań. Mówiliśmy już o tych wyszukiwaniach wektorowych. Cosine similarity, czyli podobieństwo cosinusowe. My wybieramy zawsze wyszukiwanie, znaczy ja polecam wyszukiwanie hybrydowe, dlatego, że tutaj się znajduje reranking, o którym już mówiłem, więc jakby dzięki temu będziemy mieli najbardziej dopasowane fragmenty do naszych pytań i kontent po prostu będzie dużo lepszy. Okej, z listy wybierzcie sobie ten base multimodal generic ranker. No i to w zasadzie tyle. Na razie nie konfigurujemy nic więcej. Zrobimy sobie najprostszy na świecie trening. Teraz, teraz będzie indeksacja tego na wewnętrznej bazie. Jakbyśmy chcieli robić to w N8men to trzeba by sobie połączyć Qdranta, którego pokazywał Roman i tam wiele innych historii zrobić. Natomiast w DeFi no to w sumie wszystko jak widzicie jest zrobione. To jest ogromna przewaga DeFia i to mamy zaindeksowane już na bazach wektorowych z wszystkimi bajerami, rerankingami i tak dalej. No i widzicie, tutaj są te fragmenty i jest wszystko w porządku i, i ekstra. Natomiast możemy sobie dokonać jakiegoś tam testu, żeby zobaczyć właśnie te niepodobieństwa sinusoidowe, si-sinusoidowe, cosinusowe tylko, tylko właśnie reranking. Zobaczcie, tu macie przycisk testowania. Jak sobie klikniecie w niego-- nie wiem czy to mogę rozwinąć- mogę rozwinąć testowanie poboru. Zobaczcie. Możemy wybrać dowolny nagłówek naszego planu tekstu, czyli powiedzmy niech to będzie jakie funkcje pełni kortyzol w organizmie i ona w tym momencie z tej bazy, którą zrobiliśmy, zobaczcie, wyszuka fragmenty najlepiej dopasowane i zobaczcie właśnie tutaj mamy fragmenty najlepiej dopasowane, czyli do tego, jakie funkcje pełni w organizmie. Najbliżej według rerankingu będziesz miał, jakie funkcje pełni w organizmie, czyli to było dopasowanie główne. Jakie funkcje to może być duplikat. Widzicie 1432 znaki to mówiłem krótki mały fragment, krótki mały fragment. No to właśnie mamy mniej więcej coś takiego w tej sytuacji, czyli pierwszy dokładny wiedzę i drugą taką dookoła AI uznało no i uznało, że, że tutaj to, co jest kortyzol jakby jest też uzupełnieniem według tego rerankingu. I zobaczcie, na czym polega właśnie przewaga tego, bo może się okazać, że na przykład będziemy chcieli mieć inaczej stworzony nagłówek, czyli jakie funkcje ma kortyzol w organizmie, nie? Czyli zmienia nam się już jakby nagłówek, a on ciągle nam będzie w stanie widzicie dociągnąć to samo i zrozumieć jak kto jest blisko, prawda? To jest właśnie właśnie, właśnie tutaj możemy sobie to poćwiczyć. Albo jakie funkcje ma kortyzol u człowieka? Po prostu jakie funkcje ma kortyzol, nie? No i widzicie, cały czas nam dobiera i tutaj faktycznie te skory się troszeczkę zmieniają, bo troszkę nam się to, to odchyla. Ale jakie funkcje posiada? No i zawsze nam to zadziała, nieważne jak to będzie zapytane, no to mamy tą odpowiedź, którą powinniśmy, powinniśmy mieć dzięki rerankingowi tak to działa, rozmawialiśmy o tym także mega, mega, mega fajnie działa. No to cóż.Mamy zbudowanego RAGa, zrobiliśmy to ręcznie. Teraz pewnie fajnym procesem będzie automatyzacja, żeby to nam się robiło automatycznie. Czyli po prostu dodamy kolejny, kolejną jednostkę w naszym, w naszym Exceli i automatycznie nam się to zaindeksuje, bo ręcznie, no ręcznie miło, ale chcemy sobie to automatyzować. Już Wam to pokazuję. A więc tak powiedzmy, to są nasze nagłówki, które wybraliśmy i tu mamy statusy generacji, powiedzmy generuj, to generuj będzie miało za zadanie stworzyć RAG i w kolejnej lekcji dokleimy do tego jeszcze jeden krok, który Wam pokażę w kolejnej lekcji i zapisać nam automatycznie do, do Devia, tutaj do, do tej, do tej, do tej bazy wiedzy, żeby mieć pewność, że to zostało napisane automatycznie, wyłączymy sobie to, co już jakby wgraliśmy ręcznie sobie zobaczymy, że jest wyłączone. Po kolei. Jesteśmy w Make'u. Tworzymy oczywiście nowy scenariusz. Podstawy tych scenariuszy kojarzycie? To może zróbmy w ten sposób, że, żeby było szybciej sobie duplikujemy scenariusz. Nazwiemy go krok trzy RAG. Dobra, mamy, mamy zduplikowane. Ja szybciutko już to pokazuję jak to robimy. Czym wchodzimy do procesu? Oczywiście macie wszystkie eksporty udostępnione, możecie się tym bawić. Do procesu wchodzimy keywordem, keywordem, linguagem i headingami. Dobra fraza język, kosz, kosz. Powiedzmy niech to będą nagłówki. Naszymi nagłówkami nic nie jest nagłówki konkurencji tylko naszymi nagłówkami jest to o, czyli nasze nagłówki to jest, nagłówki konkurencji, nagłówki rozbudowane nagłówki jako pytania. O nie jest to jest niepodpisane, ale o kolumna o to są nasze nagłówki generacji Język tam się nic nie zmienia. Dobra i teraz tak, tutaj nam się zmienia warunek, bo jesteśmy już przy N i N musi być na statusie generuj. Dobra status N i jest generuj dobra. Tutaj standardowo macie to zabezpieczenie, że już słowo musi istnieć, to jest jasne. No i fajnie szybko idzie, bo teraz już możemy to wysłać do Defy. Jeśli chodzi o Defy to mamy sobie to spiszemy do pliku tego samego keyword language i heading. Dobra, to czego potrzebujemy zwyczajowo to jest dostęp do API naszej aplikacji. Aplikacje w Defy są rozróżniane kluczem API. Każda ma swój dedykowany klucz. To jest właśnie, chyba zapomniałem Wam powiedzieć. Kto się śpieszy ten się wyżył. Jak się człowiek śpieszy to się diabeł cieszy. Dobra, mamy klucz. Dobra i teraz tak wracamy do Make'a. I co tutaj zmieniamy? Zasadniczo klucz, bo mamy nową aplikację. To jest klucz. Tutaj mamy nasze, naszego Jasona. Nam się zmieniają zmienne, bo keyword jest. Dobra jest. Language jest. Mamy headings trzeba wysłać headings, czyli niech to będzie keyword language headings. Pamiętajcie, że w Jasonie na końcu nie ma nigdy przecinka. Ostatni record, czyli już możemy sobie skopiować tutaj to, a w to miejsce lądują nam nagłówki. Dobra, no i nazwijmy sobie to RAG. I zobaczcie, to nam zbuduje RAGa. Na razie wykonamy sobie tą funkcję, bo, bo musimy się nauczyć co i jak w procesie, więc tutaj na razie nic nie będziemy zapisywać, bo na razie nic nie mamy. OK, odpalamy pierwszy raz proces, żeby się Make nauczył odpowiedzi i zaraz wracamy z ciągiem dalszym, z dalszym ciągiem. Dobra, wracamy. Operacja została wykonana po raz pierwszy i to co otrzymaliśmy to pytania dokładne i pytania ogólne. Także spoko i teraz trzeba by się zapisać do naszego RAGu. Zobaczcie, to jest nasza baza wiedzy. Ale jak sobie wejdziecie na stronę główną, zobaczycie tutaj macie dostęp do API i tutaj znajduje się Knowledge API. Całkiem ciekawa dokumentacja. Co i jak my tu możemy, możemy zrobić. I tutaj widzicie, że możemy zrobić dokument Create by text z Dataset ID i tutaj troszeczkę jakieś tam funkcje, które możemy przesłać to, to jest response.Eee, tu jest procesowanie, jak to jest procesowane data row i tak dalej. Ehm, do, do i się-- i to się nawet automatycznie zaindeksuje. Czyli to, co chcemy, to bierzemy klucz API. O, to jest klucz. Ja sobie już przygotowałem na tą okoliczność ściągawkę, żeby nie rozkminiać tego Jasona. Będzie udostępniony w automatyzacji. To jest mój klucz, a te klucze i tak pokazuję, więc jakby. Eee, tak to wygląda. I dokładamy sobie tutaj jeden bloczek nowy. http request, make request i zobaczcie. Tutaj dajemy sobie post. No i możemy wziąć ten URL. Tutaj nie ma tego URL tylko tu jest ten. Ale ja sobie też przygotowałem ten URL. Co do zasady pokażę jak to zrobić. Tu jest URL API. Tu jest dataset, czyli mniej więcej ten URL będzie wyglądał w ten sposób. I to dokładnie on będzie wyglądał w ten sposób, jak tutaj, więc kopiujemy sobie stąd. Zobaczcie. Tu brakuje dataset ID w adresie URL. Skąd go wziąć? Wracamy do wiedzy. Wiedza. Wracamy do wiedzy. Klikamy w naszą wiedzę, która się nazywa Kortyzol i to jest ten w adresie URL. To jest to, to jest ten ciąg znaków w adresie URL. To jest właśnie ten kod. Dataset ID. Kopiujemy ten adres. Wklejamy. Proszę bardzo. Metoda POST. Autoryzacja zgodnie ze standardem authorization. Carrier i klucz. Body type raw content type Jason i request. Ja tutaj przygotowałem jakby swoje reguły i one dobrze działają, bo tu mamy jakiś tryb automatyczny, a my robiliśmy tam konfigurację tego, że ma być high quality separator i tak dalej. To są moje reguły. One są udostępnione w tej automatyzacji, więc możecie śmiało z nich korzystać. Wklejam tutaj i żeby zaindeksować tą wiedzę potrzebuję tylko dwóch parametrów. Pierwszy to jest nazwa, czyli nazwa pliku. Co będzie naszą nazwą pliku? Ano fraza kluczowa. A co będzie naszym tekstem? No odpowiedź z, z stąd. Tylko nie zrobiliśmy jednej rzeczy. Trzeba to zabezpieczyć. Zapiszmy i zobaczcie. Tutaj trzeba po raz kolejny dodać moduł Jason Transform. To dotyczy Jason. I transformować odpowiedź z Raga. Już wiemy dlaczego. Żeby nie robiło problemów, czyli ogólne, nazywamy to wiedza ogólna. I tutaj trzeba dodać moduł Jason Transform Object data output. Ogólne czy tam dokładne? Zaraz sobie sprawdzimy, czy mamy wiedzę. Ogólna jest dokładna, czyli ona jest dokładna. Tak, to jest wiedza dokładna. A tu jest wiedza ogólna. I mamy ogólne-- mamy ogólne. Dobra, teraz możemy to wysyłać do zasady możemy to dać w jednym. Dokładne, ogólne. Usuńmy to. Będzie łatwiej. Dajmy to jako wiedza. I teraz dajemy to, jako tekst. No i tyle. No i tyle. I O Parse output oczywiście tu musi być zawsze zaznaczony. W tym przypadku nie musi, ale i nazwijmy sobie ten bloczek powiedzmy zapis do Raga. No i okej, zobaczcie, to już zaraz będzie funkcjonować. Natomiast trzeba by sobie odłożyć status, bo w Google Sheets na tym kroku nic nie potrzebujemy. Dajemy mu status RAG i dajemy do status ok, po prostu, żeby wiedzieć, że to jest okejka. W kolumnie P zapiszemy mu ok. I zmieńmy mu status w kolumnie N na gotowe. N na N. N na gotowe. No to słuchajcie, testujemy czy coś nam się wydarzy. Odpalamy proces i wracamy po krótkiej przerwie. No dobra, jak widzimy proces się udał. Mamy zbudowaną wiedzę do RAGU, ale mamy ją też jak widzimy zaindeksowaną. Mam nadzieję, że mamy. Zaraz się przekonamy, czy to, czy to się, czy to się wydarzyło. Okej, idziemy do naszego RAGU. Tutaj mamy tą wiedzę wyłączoną, żeby nie było, to było tam wgrane ręcznie. Odśwież.No i widzimy, co to jest kortyzol i to jest jakby no, w tym przypadku, no już widzicie, piętnaście tysięcy słów to jest sztuczna inteligencja, ona za każdym razem poda inaczej i już mamy zaindeksowaną wiedzę automatycznie, czyli dodając każdą kolejną sprawę kluczową do, do naszej bazy danych, no to ona będzie nam się indeksować automatycznie. No i zobaczcie, po raz kolejny mamy to, co mieliśmy, mamy testowanie poboru. Zróbmy sobie wyrywkowo jakiś teścik, czy na pewno nam to wszystko funkcjonuje. Powiedzmy, jakie są przyczyny i objawy niedoboru kortyzolu? Niech to będzie pytanie testowe, czy mamy wszystko na pewno dobrze zaindeksowane. A no proszę bardzo, mamy zaindeksowane, opisane metrykami, także, także fantastycznie. Widzicie, jakie są przyczyny i objawy niedoboru kortyzolu opisane tu i to jest fantastyczne. Jakie są objawy obniżonego poziomu kortyzolu i wiecie jaka jest różnica między obniżonym a niedoborem, prawda? Czyli, czyli co do zasady widzicie, na tym polega właśnie ten reranking. No dobra, czy w naszym pliku mamy status ok? No to jak mamy ok, to jesteśmy bardzo szczęśliwi. Czyli nasz RAG jest zbudowany i funkcjonuje. Ja w tym momencie tą automatyzację również zapisuję, dla Was będzie udostępniona. I uwaga! Została nam w następnym kroku już tylko jedna automatyzacja i dopiero będziemy-- znaczy dopiero albo już będziemy generować content. Także dzięki za tą lekcję o RAGU i budowie i automatyzacji. No i co? W następnej lekcji będziemy mówić o tym content briefingu, briefingu przed generacją i powiem Wam dlaczego tutaj poszliśmy do Google jeszcze raz przeszukiwać i odpowiadać sobie na te pytania, a nie, a nie wykorzystywaliśmy wiedzę, którą znaleźliśmy tutaj. Po prostu ją wykorzystamy w następnym kroku w procesie. Dzięki. Słyszymy się w następnej lekcji o content briefingu do generacji. Cześć!

---

**Powiązane materiały:**
- Notatka z lekcji: [T8L05_Tworzenie_tresci_z_AI_Budowa_bazy_wiedzy_RAG.md](./T8L05_Tworzenie_tresci_z_AI_Budowa_bazy_wiedzy_RAG.md)
- README Tygodnia 8: [Materiały tygodnia](../README.md) 